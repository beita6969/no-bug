#!/usr/bin/env python3
"""
æµ‹è¯•æ•°æ®é›†ä¸“å±Judgeç³»ç»Ÿ
"""
import sys
import os

# æ·»åŠ è·¯å¾„
sys.path.insert(0, '/home/yijia/.claude/11/integrated_aflow_roll/src')

from judge_prompt_loader import JudgePromptLoader

def test_judge_prompt_loader():
    """æµ‹è¯•Judge PromptåŠ è½½å™¨"""
    print("="*60)
    print("æµ‹è¯•1: Judge PromptåŠ è½½å™¨åŸºæœ¬åŠŸèƒ½")
    print("="*60)

    loader = JudgePromptLoader()
    stats = loader.get_stats()

    print(f"\nâœ… åŠ è½½å™¨åˆå§‹åŒ–æˆåŠŸ")
    print(f"æ€»æ•°æ®é›†é…ç½®: {stats['total_datasets']}")
    print(f"å¯ç”¨æ•°æ®é›†: {', '.join(stats['enabled_datasets'])}")
    print(f"ç¦ç”¨æ•°æ®é›†: {', '.join(stats['disabled_datasets'])}")

    print("\n" + "="*60)
    print("æµ‹è¯•2: ä¸åŒæ•°æ®é›†çš„Promptå†…å®¹")
    print("="*60)

    # æµ‹è¯•GSM8K
    print("\n[GSM8K Prompt]")
    prompt = loader.get_judge_prompt(source='gsm8k', problem_type='math')
    print(f"é•¿åº¦: {len(prompt)} å­—ç¬¦")
    print(f"åŒ…å«'####': {'####' in prompt}")
    print(f"åŒ…å«'<<calc>>': {'<<calc>>' in prompt}")
    print(f"åŒ…å«'GSM8K': {'GSM8K' in prompt}")
    print(f"\nå‰200å­—ç¬¦:\n{prompt[:200]}...")

    # æµ‹è¯•Math
    print("\n[Math Dataset Prompt]")
    prompt = loader.get_judge_prompt(source='math', problem_type='math')
    print(f"é•¿åº¦: {len(prompt)} å­—ç¬¦")
    print(f"åŒ…å«'MATH Dataset': {'MATH Dataset' in prompt}")
    print(f"åŒ…å«'LaTeX': {'LaTeX' in prompt}")
    has_frac = '\\\\frac' in prompt
    print(f"åŒ…å«'\\\\frac': {has_frac}")

    # æµ‹è¯•HotpotQA
    print("\n[HotpotQA Prompt]")
    prompt = loader.get_judge_prompt(source='hotpotqa', problem_type='qa')
    print(f"é•¿åº¦: {len(prompt)} å­—ç¬¦")
    print(f"åŒ…å«'PROHIBITION': {'PROHIBITION' in prompt}")
    print(f"åŒ…å«'option letter': {'option letter' in prompt}")
    print(f"åŒ…å«'might dream': {'might dream' in prompt}")

    # æµ‹è¯•CommonsenseQA
    print("\n[CommonsenseQA Prompt]")
    prompt = loader.get_judge_prompt(source='commonsenseqa', problem_type='qa')
    print(f"é•¿åº¦: {len(prompt)} å­—ç¬¦")
    print(f"åŒ…å«'Common Sense': {'Common Sense' in prompt}")
    print(f"åŒ…å«'multiple choice': {'multiple choice' in prompt}")

    # æµ‹è¯•æœªçŸ¥æ•°æ®é›†ï¼ˆåº”è¯¥fallbackï¼‰
    print("\n[Unknown Dataset - Fallback]")
    prompt = loader.get_judge_prompt(source='unknown_dataset', problem_type='math')
    print(f"é•¿åº¦: {len(prompt)} å­—ç¬¦")
    print(f"ä½¿ç”¨Fallback: {True if 'mathematical equivalence evaluator' in prompt else False}")

    print("\n" + "="*60)
    print("æµ‹è¯•3: Codeæ•°æ®é›†çš„test_executionæ ‡å¿—")
    print("="*60)

    # æµ‹è¯•HumanEval
    should_execute = loader.should_use_test_execution('humaneval')
    print(f"\n[HumanEval] åº”è¯¥ä½¿ç”¨æµ‹è¯•æ‰§è¡Œ: {should_execute}")

    # æµ‹è¯•MBPP
    should_execute = loader.should_use_test_execution('mbpp')
    print(f"[MBPP] åº”è¯¥ä½¿ç”¨æµ‹è¯•æ‰§è¡Œ: {should_execute}")

    # æµ‹è¯•Mathï¼ˆä¸åº”è¯¥ä½¿ç”¨æµ‹è¯•æ‰§è¡Œï¼‰
    should_execute = loader.should_use_test_execution('math')
    print(f"[Math] åº”è¯¥ä½¿ç”¨æµ‹è¯•æ‰§è¡Œ: {should_execute}")

    print("\n" + "="*60)
    print("æµ‹è¯•4: æ•°æ®é›†æ˜ å°„")
    print("="*60)

    print(f"\næ•°æ®é›†æ˜ å°„è¡¨:")
    for source, dataset in stats['dataset_mappings'].items():
        print(f"  {source:15} â†’ {dataset}")

    print("\nâœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")


def test_prompt_format():
    """æµ‹è¯•Promptæ ¼å¼åŒ–"""
    print("\n" + "="*60)
    print("æµ‹è¯•5: Promptæ ¼å¼åŒ–åŠŸèƒ½")
    print("="*60)

    loader = JudgePromptLoader()

    # æ¨¡æ‹ŸçœŸå®æ•°æ®
    test_cases = [
        {
            'source': 'gsm8k',
            'problem_type': 'math',
            'problem': 'Natalia sold clips to 48 of her friends in April.',
            'prediction': '\\boxed{72}',
            'ground_truth': 'Natalia sold 48/2 = <<48/2=24>>24...\\n#### 72'
        },
        {
            'source': 'hotpotqa',
            'problem_type': 'qa',
            'problem': 'When are you likely to dream?',
            'prediction': 'E',
            'ground_truth': 'might dream'
        },
        {
            'source': 'math',
            'problem_type': 'math',
            'problem': 'Simplify: 1/2 + 1/4',
            'prediction': '\\boxed{0.75}',
            'ground_truth': '\\frac{3}{4}'
        }
    ]

    for i, case in enumerate(test_cases, 1):
        print(f"\n[æµ‹è¯•ç”¨ä¾‹ {i}: {case['source']}]")
        prompt_template = loader.get_judge_prompt(
            source=case['source'],
            problem_type=case['problem_type']
        )

        # æ ¼å¼åŒ–promptï¼ˆæ‰‹åŠ¨æ›¿æ¢ï¼Œé¿å…format()è§£æXMLæ ‡ç­¾ï¼‰
        try:
            formatted_prompt = prompt_template.replace('{{problem}}', case['problem'])
            formatted_prompt = formatted_prompt.replace('{{prediction}}', case['prediction'])
            formatted_prompt = formatted_prompt.replace('{{ground_truth}}', case['ground_truth'])
            print(f"âœ… æ ¼å¼åŒ–æˆåŠŸ")
            print(f"Predictionåœ¨Promptä¸­: {case['prediction'] in formatted_prompt}")
            print(f"Ground Truthåœ¨Promptä¸­: {case['ground_truth'] in formatted_prompt}")
            print(f"æ€»é•¿åº¦: {len(formatted_prompt)} å­—ç¬¦")
        except Exception as e:
            print(f"âŒ æ ¼å¼åŒ–å¤±è´¥: {e}")
            raise  # è®©æµ‹è¯•çœŸæ­£å¤±è´¥

    print("\nâœ… Promptæ ¼å¼åŒ–æµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    try:
        test_judge_prompt_loader()
        test_prompt_format()
        print("\n" + "="*60)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ•°æ®é›†ä¸“å±Judgeç³»ç»Ÿå·¥ä½œæ­£å¸¸")
        print("="*60)
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
