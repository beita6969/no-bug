#!/usr/bin/env python3
"""
æ•°æ®ç®¡ç†å™¨ - æ··åˆæ•°æ®é›†åŠ è½½å’Œé‡‡æ ·
"""
import json
import random
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from collections import defaultdict

class DataManager:
    """æ··åˆæ•°æ®é›†ç®¡ç†å™¨"""

    def __init__(
        self,
        data_dir: str = "data",
        domain_ratios: Optional[Dict[str, float]] = None,
        shuffle: bool = True
    ):
        """
        Args:
            data_dir: æ•°æ®ç›®å½•
            domain_ratios: é¢†åŸŸé‡‡æ ·æ¯”ä¾‹ï¼Œå¦‚ {"math": 0.4, "code": 0.3, "qa": 0.3}
            shuffle: æ˜¯å¦æ‰“ä¹±æ•°æ®
        """
        self.data_dir = Path(data_dir)
        self.domain_ratios = domain_ratios or {"math": 0.4, "code": 0.3, "qa": 0.3}
        self.shuffle = shuffle

        # åŠ è½½çš„æ•°æ®
        self.train_data = {"math": [], "code": [], "qa": []}
        self.val_data = {"math": [], "code": [], "qa": []}
        self.test_data = {"math": [], "code": [], "qa": []}

        # å½“å‰è¿­ä»£ä½ç½®
        self.current_indices = {"math": 0, "code": 0, "qa": 0}

    def load_data(self, split: str = "train") -> Dict[str, List[Dict]]:
        """åŠ è½½æŒ‡å®šåˆ†å‰²çš„æ•°æ®"""
        data_by_type = defaultdict(list)
        source_stats = defaultdict(int)  # ç»Ÿè®¡sourceå­—æ®µ

        # 1. Load HumanEval code data (NEW - proper format)
        humaneval_file = self._get_humaneval_file(split)
        if humaneval_file and humaneval_file.exists():
            with open(humaneval_file, 'r') as f:
                for line in f:
                    if line.strip():
                        sample = json.loads(line)
                        # Convert HumanEval format to our format
                        converted = self._convert_humaneval_sample(sample)
                        data_by_type["code"].append(converted)
                        source_stats["humaneval"] += 1
            print(f"âœ… åŠ è½½ HumanEval code: {len(data_by_type['code'])} æ ·æœ¬")

        # 2. Load from processed directory for test/val (contains source field)
        if split in ["val", "test"]:
            # éªŒè¯é›†ä½¿ç”¨balanced_val.jsonlï¼ˆå‡åŒ€åˆ†é…ï¼‰
            if split == "val":
                dataset_file = self.data_dir / "balanced_val.jsonl"
                if not dataset_file.exists():
                    # åå¤‡ï¼šä½¿ç”¨processedç›®å½•
                    dataset_file = self.data_dir / "processed/val_mixed.jsonl"
                    print(f"âš ï¸  balanced_val.jsonlä¸å­˜åœ¨ï¼Œä½¿ç”¨processed/val_mixed.jsonl")
            else:
                # æµ‹è¯•é›†ä½¿ç”¨processedç›®å½•
                dataset_file = self.data_dir / f"processed/{split}_mixed.jsonl"
        else:
            # è®­ç»ƒæ•°æ®ä½¿ç”¨mixedç›®å½•
            if split == "train":
                # ä¼˜å…ˆä½¿ç”¨ä¿®å¤åçš„åŒ…å«MATHçš„æ•°æ®é›†
                fixed_file = self.data_dir / "mixed/train_mixed_with_math_fixed.jsonl"
                math_file = self.data_dir / "mixed/train_mixed_with_math.jsonl"
                balanced_file = self.data_dir / "mixed/train_mixed_balanced.jsonl"

                if fixed_file.exists():
                    dataset_file = fixed_file
                    print(f"âœ… ä½¿ç”¨ä¿®å¤åçš„MATHæ•°æ®è®­ç»ƒé›†: {fixed_file.name}")
                elif math_file.exists():
                    dataset_file = math_file
                    print(f"âœ… ä½¿ç”¨åŒ…å«MATHæ•°æ®çš„è®­ç»ƒé›†: {math_file.name}")
                elif balanced_file.exists():
                    dataset_file = balanced_file
                else:
                    dataset_file = self.data_dir / f"mixed/{split}_mixed.jsonl"
            else:
                dataset_file = self.data_dir / f"mixed/{split}_mixed.jsonl"
            if not dataset_file.exists():
                dataset_file = self.data_dir / f"{split}/mixed_dataset.jsonl"

        if dataset_file.exists():
            with open(dataset_file, 'r') as f:
                for line in f:
                    if line.strip():
                        sample = json.loads(line)

                        # ğŸ”´ è¿‡æ»¤MBPPæ•°æ®é›† - æ•°æ®è´¨é‡é—®é¢˜
                        if sample.get("source") == "mbpp":
                            continue

                        problem_type = sample.get("problem_type", "math")
                        # ä¿ç•™sourceå­—æ®µï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                        if "source" in sample:
                            source_stats[sample["source"]] += 1
                        data_by_type[problem_type].append(sample)

        # æ‰“ä¹±
        if self.shuffle:
            for ptype in data_by_type:
                random.shuffle(data_by_type[ptype])

        print(f"âœ… åŠ è½½ {split.upper()} æ•°æ®:")
        for ptype, samples in data_by_type.items():
            print(f"  {ptype}: {len(samples)} æ ·æœ¬")

        # æ‰“å°sourceç»Ÿè®¡
        if source_stats:
            print(f"\nğŸ“Š æ•°æ®æºåˆ†å¸ƒ:")
            for source, count in sorted(source_stats.items()):
                print(f"  {source}: {count} æ ·æœ¬")

        return dict(data_by_type)

    def _get_humaneval_file(self, split: str) -> Optional[Path]:
        """è·å–HumanEvalæ–‡ä»¶è·¯å¾„"""
        if split == "train":
            file_path = self.data_dir / "humaneval/humaneval_full.jsonl"
        elif split == "val":
            file_path = self.data_dir / "humaneval/humaneval_validate.jsonl"
        elif split == "test":
            file_path = self.data_dir / "humaneval/humaneval_test.jsonl"
        else:
            return None

        return file_path if file_path.exists() else None

    def _convert_humaneval_sample(self, sample: Dict) -> Dict:
        """
        è½¬æ¢HumanEvalæ ¼å¼åˆ°æˆ‘ä»¬çš„æ ¼å¼

        HumanEval format:
        {
            "task_id": "HumanEval/0",
            "prompt": "def has_close_elements(...):\n    ...",
            "entry_point": "has_close_elements",
            "canonical_solution": "    for idx...",
            "test": "def check(candidate):\n    assert..."
        }

        Our format (extended):
        {
            "problem": str,
            "problem_type": "code",
            "source": "humaneval",  # NEW - æ·»åŠ sourceå­—æ®µ
            "tag": "humaneval",
            "ground_truth": str,  # canonical_solution
            "entry_point": str,  # NEW
            "prompt": str,       # NEW - full function signature
            "test": str          # NEW - test cases
        }
        """
        return {
            "problem": sample["prompt"],  # Full function signature + docstring
            "problem_type": "code",
            "source": "humaneval",  # æ·»åŠ sourceå­—æ®µç”¨äºè¿½è¸ª
            "tag": "humaneval",
            "task_id": sample.get("task_id", ""),
            "ground_truth": sample["canonical_solution"],
            "entry_point": sample["entry_point"],
            "prompt": sample["prompt"],
            "test": sample["test"]
        }

    def initialize(self):
        """åˆå§‹åŒ–æ‰€æœ‰æ•°æ®"""
        print("=" * 60)
        print("ğŸ“‚ åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨")
        print("=" * 60)

        self.train_data = self.load_data("train")
        self.val_data = self.load_data("val")
        self.test_data = self.load_data("test")

        # éªŒè¯æ•°æ®
        total_train = sum(len(samples) for samples in self.train_data.values())
        total_val = sum(len(samples) for samples in self.val_data.values())
        total_test = sum(len(samples) for samples in self.test_data.values())

        print(f"\nğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
        print(f"  è®­ç»ƒé›†: {total_train} æ ·æœ¬")
        print(f"  éªŒè¯é›†: {total_val} æ ·æœ¬")
        print(f"  æµ‹è¯•é›†: {total_test} æ ·æœ¬")

        print("\nğŸ¯ é‡‡æ ·æ¯”ä¾‹:")
        for domain, ratio in self.domain_ratios.items():
            print(f"  {domain}: {ratio*100:.1f}%")

        print("=" * 60)

    def sample_batch(
        self,
        batch_size: int,
        split: str = "train",
        domain_ratios: Optional[Dict[str, float]] = None
    ) -> List[Dict]:
        """
        æŒ‰æ¯”ä¾‹é‡‡æ ·ä¸€ä¸ªbatch

        Args:
            batch_size: batchå¤§å°
            split: æ•°æ®åˆ†å‰² (train/val/test)
            domain_ratios: è‡ªå®šä¹‰æ¯”ä¾‹ï¼ˆNoneåˆ™ä½¿ç”¨é»˜è®¤ï¼‰

        Returns:
            æ··åˆbatchæ ·æœ¬åˆ—è¡¨
        """
        ratios = domain_ratios or self.domain_ratios

        # é€‰æ‹©æ•°æ®æº
        if split == "train":
            data_source = self.train_data
        elif split == "val":
            data_source = self.val_data
        else:
            data_source = self.test_data

        # è®¡ç®—æ¯ä¸ªé¢†åŸŸçš„æ ·æœ¬æ•°
        domain_counts = {}
        remaining = batch_size

        for domain in ["math", "code", "qa"]:
            if domain in ratios:
                count = int(batch_size * ratios[domain])
                domain_counts[domain] = count
                remaining -= count

        # å°†ä½™æ•°åˆ†é…ç»™ç¬¬ä¸€ä¸ªé¢†åŸŸ
        if remaining > 0:
            first_domain = list(domain_counts.keys())[0]
            domain_counts[first_domain] += remaining

        # é‡‡æ ·
        batch = []

        for domain, count in domain_counts.items():
            if domain not in data_source or len(data_source[domain]) == 0:
                print(f"âš ï¸  {domain} æ•°æ®ä¸è¶³ï¼Œè·³è¿‡")
                continue

            domain_data = data_source[domain]

            # åœ¨çº¿å­¦ä¹ æ¨¡å¼ï¼šå¾ªç¯é‡‡æ ·
            samples = []
            for _ in range(count):
                # è·å–å½“å‰æ ·æœ¬
                idx = self.current_indices[domain] % len(domain_data)
                samples.append(domain_data[idx])

                # æ›´æ–°ç´¢å¼•
                self.current_indices[domain] += 1

                # å¦‚æœä¸€è½®ç»“æŸï¼Œé‡æ–°æ‰“ä¹±
                if self.current_indices[domain] % len(domain_data) == 0:
                    if self.shuffle:
                        random.shuffle(domain_data)

            batch.extend(samples)

        # æ‰“ä¹±batch
        if self.shuffle:
            random.shuffle(batch)

        return batch

    def get_batch_stats(self, batch: List[Dict]) -> Dict[str, int]:
        """è·å–batchçš„ç»Ÿè®¡ä¿¡æ¯"""
        stats = defaultdict(int)

        for sample in batch:
            ptype = sample.get("problem_type", "unknown")
            stats[ptype] += 1

        return dict(stats)

    def reset_indices(self):
        """é‡ç½®é‡‡æ ·ç´¢å¼•"""
        self.current_indices = {"math": 0, "code": 0, "qa": 0}
        print("âœ… é‡‡æ ·ç´¢å¼•å·²é‡ç½®")


def test_data_manager():
    """æµ‹è¯•æ•°æ®ç®¡ç†å™¨"""
    print("\n" + "=" * 60)
    print("ğŸ§ª æµ‹è¯•æ•°æ®ç®¡ç†å™¨")
    print("=" * 60)

    # åˆ›å»ºç®¡ç†å™¨
    manager = DataManager(
        data_dir="data",
        domain_ratios={"math": 0.4, "code": 0.3, "qa": 0.3}
    )

    # åˆå§‹åŒ–
    manager.initialize()

    # é‡‡æ ·æµ‹è¯•
    print("\nğŸ”¬ é‡‡æ ·æµ‹è¯•:")
    for i in range(3):
        batch = manager.sample_batch(batch_size=10, split="train")
        stats = manager.get_batch_stats(batch)

        print(f"\nBatch {i+1}:")
        print(f"  æ€»æ•°: {len(batch)}")
        print(f"  åˆ†å¸ƒ: {stats}")

        # æ˜¾ç¤ºå‰2ä¸ªæ ·æœ¬
        for j, sample in enumerate(batch[:2]):
            print(f"  æ ·æœ¬{j+1}: {sample['problem_type']} - {sample['problem'][:50]}...")


if __name__ == "__main__":
    test_data_manager()
