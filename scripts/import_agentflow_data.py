#!/usr/bin/env python3
"""
AgentFlow æ•°æ®å¯¼å…¥å·¥å…·
å°† AgentFlow é¡¹ç›®ä½¿ç”¨çš„ NQ (Search) å’Œ DeepMath (Math) æ•°æ®é›†è½¬æ¢ä¸ºæœ¬é¡¹ç›®æ”¯æŒçš„æ ¼å¼ï¼Œ
å¹¶ä¸æœ¬åœ°çš„ HumanEval (Code) æ•°æ®é›†æ··åˆï¼Œç”Ÿæˆé«˜è´¨é‡çš„è®­ç»ƒæ•°æ®ã€‚
"""
import os
import json
import random
import datasets
import pandas as pd
import numpy as np
from pathlib import Path
from typing import List, Dict, Any
from tqdm import tqdm

# é…ç½®
OUTPUT_DIR = "data/mixed"
OUTPUT_FILE = "train_agentflow_hybrid.jsonl"
HUMANEVAL_PATH = "data/humaneval/humaneval_full.jsonl"

# é‡‡æ ·æ•°é‡é…ç½® (æ ¹æ® README çš„ 4:3:3 æ¯”ä¾‹æˆ– AgentFlow çš„åŸå§‹è§„æ¨¡)
# AgentFlow åŸå§‹: ~180k total. æˆ‘ä»¬å¯èƒ½ä¸éœ€è¦è¿™ä¹ˆå¤šï¼Œæˆ–è€…å…¨éƒ¨åˆ©ç”¨ã€‚
# å»ºè®®ï¼šMath 20k, QA 20k, Code (HumanEvalåªæœ‰164ä¸ªï¼Œéœ€é‡å¤é‡‡æ ·æˆ–å¯»æ‰¾æ›´å¤š)
# è¿™é‡Œæˆ‘ä»¬å…ˆå…¨é‡åŠ è½½ï¼Œç„¶åå…è®¸ç”¨æˆ·æŒ‡å®šé‡‡æ ·æ•°
SAMPLE_COUNTS = {
    "math": 20000,  # DeepMath å¾ˆå¤§ï¼Œé‡‡æ · 20k
    "qa": 20000,    # NQ å¾ˆå¤§ï¼Œé‡‡æ · 20k
    "code": None    # None è¡¨ç¤ºä½¿ç”¨å…¨éƒ¨æœ¬åœ°æ•°æ® (HumanEval ~164)
}

def process_golden_answers(golden_answers, to_string=True):
    """
    å¤åˆ¶è‡ª AgentFlow: å¤„ç† NQ æ•°æ®é›†çš„ç­”æ¡ˆæ ¼å¼
    """
    items = []
    if isinstance(golden_answers, np.ndarray):
        items = [str(item) for item in golden_answers.flatten() if item is not None and pd.notna(item)]
    elif isinstance(golden_answers, (list, tuple)):
        items = [str(item) for item in golden_answers if item is not None and pd.notna(item)]
    elif isinstance(golden_answers, str):
        cleaned = golden_answers.strip()
        if cleaned:
            items = [cleaned]
    elif isinstance(golden_answers, (int, float, np.generic)):
        if not pd.isna(golden_answers):
            items = [str(golden_answers).strip()]
    elif golden_answers is None or (isinstance(golden_answers, str) and not golden_answers.strip()):
        items = []
    else:
        s = str(golden_answers).strip()
        if s and s != "nan":
            items = [s]

    if to_string:
        return "; ".join(items) if items else ""
    else:
        return items

def load_agentflow_qa() -> List[Dict]:
    """åŠ è½½ NQ æ•°æ®é›† (QA/Search)"""
    print("ğŸ“¥ ä¸‹è½½/åŠ è½½ NQ æ•°æ®é›† (AgentFlow Search Source)...")
    try:
        # ä½¿ç”¨ AgentFlow åŒæ¬¾æ•°æ®é›†
        dataset = datasets.load_dataset('RUC-NLPIR/FlashRAG_datasets', 'nq', split='train')
        
        processed = []
        for item in tqdm(dataset, desc="Processing NQ"):
            question = item.get("question", "").strip()
            if question and not question.endswith('?'):
                question += '?'
            
            golden_answers = item.get("golden_answers", [])
            final_result = process_golden_answers(golden_answers, to_string=True)
            
            if not final_result:
                continue

            processed.append({
                "problem": question,
                "problem_type": "qa",  # æ˜ å°„ä¸ºæˆ‘ä»¬çš„ qa ç±»å‹
                "ground_truth": final_result,
                "source": "agentflow_nq",
                "id": f"nq_{item.get('id', random.randint(0, 999999))}"
            })
        
        print(f"âœ… åŠ è½½ NQ æ•°æ®: {len(processed)} æ¡")
        return processed
    except Exception as e:
        print(f"âŒ åŠ è½½ NQ å¤±è´¥: {e}")
        return []

def load_agentflow_math() -> List[Dict]:
    """åŠ è½½ DeepMath æ•°æ®é›† (Math)"""
    print("ğŸ“¥ ä¸‹è½½/åŠ è½½ DeepMath æ•°æ®é›† (AgentFlow Math Source)...")
    try:
        # ä½¿ç”¨ AgentFlow åŒæ¬¾æ•°æ®é›†
        dataset = datasets.load_dataset('zwhe99/DeepMath-103K', split='train')
        
        processed = []
        for idx, item in enumerate(tqdm(dataset, desc="Processing DeepMath")):
            question = item.get('question') or item.get('Problem')
            solution = item.get('final_answer') or item.get('Answer')
            
            if not question or not solution:
                continue

            processed.append({
                "problem": question,
                "problem_type": "math",  # æ˜ å°„ä¸ºæˆ‘ä»¬çš„ math ç±»å‹
                "ground_truth": str(solution),
                "source": "agentflow_deepmath",
                "id": f"math_{idx}"
            })
            
        print(f"âœ… åŠ è½½ DeepMath æ•°æ®: {len(processed)} æ¡")
        return processed
    except Exception as e:
        print(f"âŒ åŠ è½½ DeepMath å¤±è´¥: {e}")
        return []

def load_local_code() -> List[Dict]:
    """åŠ è½½æœ¬åœ° Code æ•°æ®é›† (HumanEval)"""
    print("ğŸ“‚ åŠ è½½æœ¬åœ° Code æ•°æ® (HumanEval)...")
    path = Path(HUMANEVAL_PATH)
    if not path.exists():
        print(f"âŒ æœªæ‰¾åˆ°ä»£ç æ•°æ®: {path}")
        return []
    
    processed = []
    with open(path, 'r') as f:
        for line in f:
            if not line.strip(): continue
            item = json.loads(line)
            
            # è½¬æ¢ä¸ºæˆ‘ä»¬çš„è®­ç»ƒæ ¼å¼
            # æ³¨æ„ï¼šHumanEval çš„ 'prompt' æ˜¯å‡½æ•°ç­¾åï¼Œ'canonical_solution' æ˜¯å®ç°
            # æˆ‘ä»¬éœ€è¦æ„é€ ä¸€ä¸ªè®©æ¨¡å‹ç”Ÿæˆ Workflow çš„ problem
            
            # æ„é€  Problem:
            # HumanEval çš„ prompt å®é™…ä¸Šå°±æ˜¯é¢˜ç›®æè¿°ï¼ˆåŒ…å«å‡½æ•°å¤´ï¼‰
            problem_text = item.get("prompt", "")
            
            processed.append({
                "problem": problem_text,
                "problem_type": "code",
                "ground_truth": item.get("canonical_solution", ""),
                "source": "humaneval",
                "entry_point": item.get("entry_point"),
                "test": item.get("test"),
                "task_id": item.get("task_id")
            })
            
    print(f"âœ… åŠ è½½ Local Code æ•°æ®: {len(processed)} æ¡")
    return processed

def main():
    print("="*60)
    print("ğŸš€ AgentFlow æ•°æ®é›†å¯¼å…¥ä¸æ··åˆå·¥å…·")
    print("="*60)
    
    # 1. åŠ è½½å„æºæ•°æ®
    qa_data = load_agentflow_qa()
    math_data = load_agentflow_math()
    code_data = load_local_code()
    
    if not qa_data and not math_data:
        print("âŒ æœªåŠ è½½åˆ°ä»»ä½• AgentFlow æ•°æ®ï¼Œç»ˆæ­¢ã€‚")
        return

    # 2. é‡‡æ ·ä¸å¹³è¡¡
    final_data = []
    
    # Math
    if SAMPLE_COUNTS["math"] and len(math_data) > SAMPLE_COUNTS["math"]:
        print(f"âœ‚ï¸  Math æ•°æ®é‡‡æ ·: {len(math_data)} -> {SAMPLE_COUNTS['math']}")
        final_data.extend(random.sample(math_data, SAMPLE_COUNTS["math"]))
    else:
        final_data.extend(math_data)
        
    # QA
    if SAMPLE_COUNTS["qa"] and len(qa_data) > SAMPLE_COUNTS["qa"]:
        print(f"âœ‚ï¸  QA æ•°æ®é‡‡æ ·: {len(qa_data)} -> {SAMPLE_COUNTS['qa']}")
        final_data.extend(random.sample(qa_data, SAMPLE_COUNTS["qa"]))
    else:
        final_data.extend(qa_data)
        
    # Code (HumanEval å¾ˆå°‘ï¼Œå…¨éƒ¨ä¿ç•™ï¼Œç”šè‡³å¯ä»¥è€ƒè™‘è¿‡é‡‡æ ·)
    # ä¸ºäº†å¹³è¡¡ï¼Œæˆ‘ä»¬å°† HumanEval é‡å¤ N æ¬¡ï¼Œä½¿å…¶å æ¯”ä¸è‡³äºå¤ªå°ï¼ˆæ¯”å¦‚å‡‘å¤Ÿ 2000 æ¡ï¼‰
    if code_data:
        target_code_count = 2000
        repeat_factor = target_code_count // len(code_data) + 1
        print(f"ğŸ”„ Code æ•°æ®å¢å¼º: {len(code_data)} -> ~{len(code_data) * repeat_factor} (é‡å¤ {repeat_factor} æ¬¡)")
        extended_code = code_data * repeat_factor
        final_data.extend(extended_code[:target_code_count])
    else:
        print("âš ï¸  è­¦å‘Š: æ²¡æœ‰ä»»ä½• Code æ•°æ®ï¼æ¨¡å‹å°†å¤±å»ä»£ç ç”Ÿæˆèƒ½åŠ›ã€‚")

    # 3. æ‰“ä¹±
    random.shuffle(final_data)
    
    # 4. ä¿å­˜
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    output_path = os.path.join(OUTPUT_DIR, OUTPUT_FILE)
    
    print(f"\nğŸ’¾ ä¿å­˜æ··åˆæ•°æ®é›†åˆ°: {output_path}")
    with open(output_path, 'w') as f:
        for item in final_data:
            f.write(json.dumps(item) + "\n")
            
    # 5. ç»Ÿè®¡
    stats = {"math": 0, "qa": 0, "code": 0}
    for item in final_data:
        stats[item["problem_type"]] += 1
        
    print(f"âœ… å®Œæˆï¼æ€»æ ·æœ¬æ•°: {len(final_data)}")
    print(f"ğŸ“Š åˆ†å¸ƒç»Ÿè®¡: {stats}")
    print("\nğŸ’¡ å»ºè®®: è¯·åœ¨ config/training.yaml ä¸­æ›´æ–° 'train_dataset' å­—æ®µæŒ‡å‘æ­¤æ–‡ä»¶ã€‚")

if __name__ == "__main__":
    main()


