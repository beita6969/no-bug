#!/usr/bin/env python3
"""
è¯„ä¼°æ¯ä¸ªå°æ•°æ®é›†çš„å‡†ç¡®ç‡
"""
import json
import sys
from pathlib import Path
from collections import defaultdict
from typing import Dict, List

def load_test_data(test_file: str) -> List[Dict]:
    """åŠ è½½æµ‹è¯•æ•°æ®"""
    samples = []
    with open(test_file, 'r') as f:
        for line in f:
            if line.strip():
                samples.append(json.loads(line))
    return samples

def infer_dataset(sample: Dict) -> str:
    """æ¨æ–­æ ·æœ¬æ¥æºæ•°æ®é›†"""
    # æ ¹æ®sampleçš„å­—æ®µåˆ¤æ–­æ¥æº
    problem_type = sample.get('problem_type', '')

    # Mathç±»å‹
    if problem_type == 'math':
        # æ£€æŸ¥æ˜¯å¦æœ‰categoryå­—æ®µ (MATH dataset)
        if 'category' in sample or 'difficulty' in sample:
            return 'MATH'
        # æ£€æŸ¥solutioné•¿åº¦åˆ¤æ–­GSM8K (é€šå¸¸è¾ƒçŸ­)
        if 'solution' in sample:
            return 'MATH'  # é»˜è®¤å½’ç±»ä¸ºMATH
        return 'GSM8K'

    # Codeç±»å‹
    elif problem_type == 'code':
        problem = sample.get('problem', '')
        # HumanEval: Pythonå‡½æ•°å®šä¹‰å¼€å¤´
        if problem.strip().startswith('def '):
            return 'HumanEval'
        # MBPP: é€šå¸¸æœ‰æ›´è¯¦ç»†çš„æè¿°
        return 'MBPP'

    # QAç±»å‹
    elif problem_type == 'qa':
        # æ£€æŸ¥å­—æ®µåˆ¤æ–­æ¥æº
        if 'type' in sample and 'context' in sample:
            # HotpotQAæ ¼å¼
            return 'HotpotQA'
        elif 'passage' in sample:
            # CommonsenseQAæˆ–å…¶ä»–passage-based
            return 'CommonsenseQA'
        elif 'question' in sample:
            # MMLUæ ¼å¼
            return 'MMLU'
        return 'Other-QA'

    return 'Unknown'

def group_by_dataset(samples: List[Dict]) -> Dict[str, List[Dict]]:
    """æŒ‰æ•°æ®é›†åˆ†ç»„"""
    grouped = defaultdict(list)
    for sample in samples:
        dataset = infer_dataset(sample)
        grouped[dataset].append(sample)
    return grouped

def print_statistics(grouped: Dict[str, List[Dict]]):
    """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
    print("\n" + "="*70)
    print("æµ‹è¯•é›†æ•°æ®åˆ†å¸ƒ")
    print("="*70)

    total = sum(len(samples) for samples in grouped.values())
    print(f"\næ€»æ ·æœ¬æ•°: {total}\n")

    # æŒ‰ç±»å‹åˆ†ç»„ç»Ÿè®¡
    math_count = 0
    code_count = 0
    qa_count = 0

    for dataset, samples in sorted(grouped.items(), key=lambda x: -len(x[1])):
        count = len(samples)
        percentage = (count / total) * 100
        print(f"{dataset:20s}: {count:6d} ({percentage:5.1f}%)")

        # ç»Ÿè®¡ç±»å‹
        if samples:
            sample_type = samples[0].get('problem_type', '')
            if sample_type == 'math':
                math_count += count
            elif sample_type == 'code':
                code_count += count
            elif sample_type == 'qa':
                qa_count += count

    print("\n" + "-"*70)
    print(f"Mathæ€»è®¡: {math_count} ({math_count/total*100:.1f}%)")
    print(f"Codeæ€»è®¡: {code_count} ({code_count/total*100:.1f}%)")
    print(f"QAæ€»è®¡:   {qa_count} ({qa_count/total*100:.1f}%)")
    print("="*70)

def main():
    test_file = "data/test/mixed_dataset.jsonl"

    if not Path(test_file).exists():
        print(f"âŒ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
        sys.exit(1)

    print(f"ğŸ“Š åŠ è½½æµ‹è¯•æ•°æ®: {test_file}")
    samples = load_test_data(test_file)
    print(f"âœ… åŠ è½½å®Œæˆ: {len(samples)} ä¸ªæ ·æœ¬")

    print("\nğŸ” åˆ†ææ•°æ®é›†åˆ†å¸ƒ...")
    grouped = group_by_dataset(samples)

    print_statistics(grouped)

    # ä¿å­˜åˆ†ç»„ç»“æœ
    output_file = "data/test/dataset_breakdown.json"
    breakdown = {
        dataset: len(samples)
        for dataset, samples in grouped.items()
    }

    with open(output_file, 'w') as f:
        json.dump(breakdown, f, indent=2)

    print(f"\nğŸ’¾ æ•°æ®é›†åˆ†å¸ƒå·²ä¿å­˜: {output_file}")

if __name__ == "__main__":
    main()
