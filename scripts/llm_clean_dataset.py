#!/usr/bin/env python3
"""
LLM æ•°æ®æ¸…æ´—å™¨
ä½¿ç”¨æœ¬åœ°å¼ºå¤§çš„ LLM (GPT OSS 120B @ port 8002) å¯¹æ•°æ®é›†è¿›è¡Œæ·±åº¦æ‰«æã€‚
ç›®æ ‡ï¼šå‰”é™¤ "é—®é¢˜-ç­”æ¡ˆ" ä¸åŒ¹é…ã€æŒ‡ä»£ä¸æ˜æˆ–ç­”æ¡ˆé”™è¯¯çš„æ ·æœ¬ã€‚
"""

import json
import os
import asyncio
from tqdm import tqdm
from openai import OpenAI

# é…ç½®
INPUT_FILE = "11/integrated_aflow_roll/data/ready_to_train/train.jsonl"
OUTPUT_FILE = "11/integrated_aflow_roll/data/ready_to_train/train_llm_cleaned.jsonl"
BAD_CASE_FILE = "11/integrated_aflow_roll/data/ready_to_train/dropped_samples.jsonl"

LLM_CONFIG = {
    "base_url": "http://localhost:8002/v1",
    "api_key": "sk-dummy",
    "model": "/home/yijia/lhy/openai/gpt-oss-120b"
}

client = OpenAI(base_url=LLM_CONFIG["base_url"], api_key=LLM_CONFIG["api_key"])

def check_sample(item):
    """ä½¿ç”¨ LLM åˆ¤æ–­æ ·æœ¬è´¨é‡"""
    problem = item.get("problem", "")
    ground_truth = item.get("ground_truth", "")
    p_type = item.get("problem_type", "qa")
    
    # Code ç±»å‹é€šå¸¸æ¯”è¾ƒå¯é ï¼ˆä¸”ä¸Šä¸‹æ–‡å¤ªé•¿ï¼‰ï¼Œè·³è¿‡æ·±åº¦æ£€æŸ¥ï¼ŒåªåšåŸºç¡€æ£€æŸ¥
    if p_type == "code":
        if not problem or not ground_truth:
            return False, "Empty code problem or solution"
        return True, ""

    prompt = f"""Task: Verify if the following Question-Answer pair is valid, self-contained, and correct.

Question: {problem}
Ground Truth Answer: {ground_truth}

Verification Criteria:
1. Is the question meaningful and self-contained (not dependent on missing context)?
2. Is the Ground Truth answer logically correct for the question?
3. Does the Ground Truth make sense (e.g., rejecting "length and width" as a definition for "commercial paper")?

Respond with JSON only:
{{
    "valid": true/false,
    "reason": "short explanation"
}}
"""
    
    try:
        response = client.chat.completions.create(
            model=LLM_CONFIG["model"],
            messages=[
                {"role": "system", "content": "You are a strict data quality auditor."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.0,
            max_tokens=100,
            response_format={"type": "json_object"}
        )
        
        content = response.choices[0].message.content
        result = json.loads(content)
        
        return result.get("valid", False), result.get("reason", "Unknown")
        
    except Exception as e:
        print(f"âš ï¸  LLM è°ƒç”¨å¤±è´¥: {e}")
        return True, "LLM Check Failed (Assume Valid)"

def main():
    print("ğŸ§¹ å¼€å§‹ LLM æ•°æ®æ·±åº¦æ¸…æ´—...")
    print(f"  è¾“å…¥: {INPUT_FILE}")
    print(f"  æ¨¡å‹: {LLM_CONFIG['model']}")
    
    if not os.path.exists(INPUT_FILE):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {INPUT_FILE}")
        return

    # è¯»å–æ•°æ®
    with open(INPUT_FILE, 'r') as f:
        lines = f.readlines()
        
    total = len(lines)
    print(f"  æ€»æ ·æœ¬æ•°: {total}")
    
    valid_data = []
    dropped_data = []
    
    # å¹¶å‘å¤ªé«˜å¯èƒ½å‹å®æœ¬åœ°æœåŠ¡ï¼Œè¿™é‡Œä½¿ç”¨ç®€å•çš„é¡ºåºå¤„ç†æˆ–å°æ‰¹æ¬¡
    # ä¸ºäº†è¿›åº¦å¯è§ï¼Œç”¨ tqdm
    for line in tqdm(lines):
        item = json.loads(line)
        is_valid, reason = check_sample(item)
        
        if is_valid:
            valid_data.append(item)
        else:
            item["drop_reason"] = reason
            dropped_data.append(item)
            
    # ä¿å­˜ç»“æœ
    print(f"\nğŸ“Š æ¸…æ´—ç»“æœ:")
    print(f"  âœ… ä¿ç•™: {len(valid_data)} ({len(valid_data)/total*100:.1f}%)")
    print(f"  ğŸ—‘ï¸  å‰”é™¤: {len(dropped_data)} ({len(dropped_data)/total*100:.1f}%)")
    
    with open(OUTPUT_FILE, 'w') as f:
        for item in valid_data:
            f.write(json.dumps(item) + "\n")
            
    with open(BAD_CASE_FILE, 'w') as f:
        for item in dropped_data:
            f.write(json.dumps(item) + "\n")
            
    print(f"\nğŸ’¾ å·²ä¿å­˜æ¸…æ´—åçš„æ•°æ®: {OUTPUT_FILE}")
    print(f"ğŸ’¾ å·²ä¿å­˜å‰”é™¤æ ·æœ¬(ä¾›æ£€æŸ¥): {BAD_CASE_FILE}")

if __name__ == "__main__":
    main()


