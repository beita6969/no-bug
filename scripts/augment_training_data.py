#!/usr/bin/env python3
"""
å¢å¼ºè®­ç»ƒæ•°æ®ï¼šæå‡Codeæ ·æœ¬æ¯”ä¾‹

å½“å‰: Code 0.09% (128/147432)
ç›®æ ‡: Code 10%
æ–¹æ³•: é‡å¤Codeæ ·æœ¬
"""
import json
import random
from pathlib import Path
from typing import List, Dict

def load_jsonl(file_path: str) -> List[Dict]:
    """åŠ è½½JSONLæ–‡ä»¶"""
    samples = []
    with open(file_path, 'r') as f:
        for line in f:
            if line.strip():
                samples.append(json.loads(line))
    return samples

def save_jsonl(samples: List[Dict], file_path: str):
    """ä¿å­˜JSONLæ–‡ä»¶"""
    with open(file_path, 'w') as f:
        for sample in samples:
            f.write(json.dumps(sample, ensure_ascii=False) + '\n')

def augment_training_data(
    input_file: str,
    output_file: str,
    target_code_ratio: float = 0.10,
    add_humaneval: bool = True
):
    """
    å¢å¼ºè®­ç»ƒæ•°æ®

    Args:
        input_file: åŸå§‹è®­ç»ƒé›†
        output_file: å¢å¼ºåçš„è®­ç»ƒé›†
        target_code_ratio: ç›®æ ‡Codeæ ·æœ¬æ¯”ä¾‹ (é»˜è®¤10%)
        add_humaneval: æ˜¯å¦æ·»åŠ HumanEvalæ•°æ®
    """
    print("="*70)
    print("è®­ç»ƒæ•°æ®å¢å¼º")
    print("="*70)

    # 1. åŠ è½½åŸå§‹æ•°æ®
    print(f"\nğŸ“‚ åŠ è½½åŸå§‹è®­ç»ƒé›†: {input_file}")
    samples = load_jsonl(input_file)
    print(f"âœ… åŠ è½½å®Œæˆ: {len(samples)} ä¸ªæ ·æœ¬")

    # 2. åˆ†ç±»ç»Ÿè®¡
    math_samples = [s for s in samples if s.get('problem_type') == 'math']
    qa_samples = [s for s in samples if s.get('problem_type') == 'qa']
    code_samples = [s for s in samples if s.get('problem_type') == 'code']

    print(f"\nğŸ“Š åŸå§‹åˆ†å¸ƒ:")
    print(f"  Math: {len(math_samples)} ({len(math_samples)/len(samples)*100:.2f}%)")
    print(f"  QA:   {len(qa_samples)} ({len(qa_samples)/len(samples)*100:.2f}%)")
    print(f"  Code: {len(code_samples)} ({len(code_samples)/len(samples)*100:.2f}%)")

    # 3. æ·»åŠ HumanEvalæ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    humaneval_samples = []
    if add_humaneval:
        humaneval_file = "data/humaneval/humaneval_full.jsonl"
        if Path(humaneval_file).exists():
            print(f"\nğŸ“¥ åŠ è½½HumanEvalæ•°æ®: {humaneval_file}")
            humaneval_raw = load_jsonl(humaneval_file)

            # è½¬æ¢HumanEvalæ ¼å¼ä¸ºç»Ÿä¸€æ ¼å¼
            for hr in humaneval_raw:
                sample = {
                    'problem': hr.get('prompt', ''),
                    'problem_type': 'code',
                    'ground_truth': hr.get('canonical_solution', ''),
                    'entry_point': hr.get('entry_point', ''),
                    'test': hr.get('test', ''),
                    'task_id': hr.get('task_id', '')
                }
                humaneval_samples.append(sample)

            print(f"âœ… HumanEval: {len(humaneval_samples)} ä¸ªæ ·æœ¬")
            code_samples.extend(humaneval_samples)

    # 4. è®¡ç®—éœ€è¦çš„Codeæ ·æœ¬æ•°
    total_non_code = len(math_samples) + len(qa_samples)
    # target_code_ratio = code / (code + non_code)
    # code = target_code_ratio * (code + non_code)
    # code = target_code_ratio * total
    # total = code / target_code_ratio
    # non_code = total - code = code / target_code_ratio - code = code * (1 - target_code_ratio) / target_code_ratio

    target_code_count = int(total_non_code * target_code_ratio / (1 - target_code_ratio))
    current_code_count = len(code_samples)

    print(f"\nğŸ¯ ç›®æ ‡Codeæ ·æœ¬æ•°: {target_code_count}")
    print(f"   å½“å‰Codeæ ·æœ¬æ•°: {current_code_count}")
    print(f"   éœ€è¦å¢åŠ : {target_code_count - current_code_count}")

    # 5. é‡å¤Codeæ ·æœ¬è¾¾åˆ°ç›®æ ‡
    if current_code_count < target_code_count:
        repetitions = target_code_count // current_code_count
        remainder = target_code_count % current_code_count

        print(f"\nğŸ”„ é‡å¤ç­–ç•¥:")
        print(f"   å®Œæ•´é‡å¤: {repetitions} æ¬¡")
        print(f"   é¢å¤–æ ·æœ¬: {remainder} ä¸ª")

        augmented_code_samples = code_samples * repetitions
        if remainder > 0:
            # éšæœºé€‰æ‹©é¢å¤–æ ·æœ¬
            extra_samples = random.sample(code_samples, remainder)
            augmented_code_samples.extend(extra_samples)

        print(f"âœ… å¢å¼ºåCodeæ ·æœ¬: {len(augmented_code_samples)}")
    else:
        augmented_code_samples = code_samples
        print(f"âœ… Codeæ ·æœ¬å·²è¶³å¤Ÿï¼Œæ— éœ€é‡å¤")

    # 6. åˆå¹¶æ‰€æœ‰æ ·æœ¬
    final_samples = math_samples + qa_samples + augmented_code_samples

    # 7. æ‰“ä¹±é¡ºåº
    print(f"\nğŸ”€ æ‰“ä¹±æ ·æœ¬é¡ºåº...")
    random.shuffle(final_samples)

    # 8. ç»Ÿè®¡æœ€ç»ˆåˆ†å¸ƒ
    final_math = sum(1 for s in final_samples if s.get('problem_type') == 'math')
    final_qa = sum(1 for s in final_samples if s.get('problem_type') == 'qa')
    final_code = sum(1 for s in final_samples if s.get('problem_type') == 'code')

    print(f"\nğŸ“Š æœ€ç»ˆåˆ†å¸ƒ:")
    print(f"  Math: {final_math} ({final_math/len(final_samples)*100:.2f}%)")
    print(f"  QA:   {final_qa} ({final_qa/len(final_samples)*100:.2f}%)")
    print(f"  Code: {final_code} ({final_code/len(final_samples)*100:.2f}%)")
    print(f"  æ€»è®¡: {len(final_samples)}")

    # 9. ä¿å­˜
    print(f"\nğŸ’¾ ä¿å­˜å¢å¼ºè®­ç»ƒé›†: {output_file}")
    save_jsonl(final_samples, output_file)
    print(f"âœ… ä¿å­˜å®Œæˆ!")

    # 10. ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'original_total': len(samples),
        'original_math': len(math_samples),
        'original_qa': len(qa_samples),
        'original_code': len(code_samples) - len(humaneval_samples),
        'humaneval_added': len(humaneval_samples),
        'final_total': len(final_samples),
        'final_math': final_math,
        'final_qa': final_qa,
        'final_code': final_code,
        'target_code_ratio': target_code_ratio,
        'actual_code_ratio': final_code / len(final_samples)
    }

    stats_file = output_file.replace('.jsonl', '_stats.json')
    with open(stats_file, 'w') as f:
        json.dump(stats, f, indent=2)
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜: {stats_file}")

    print("\n" + "="*70)
    print("âœ… æ•°æ®å¢å¼ºå®Œæˆ!")
    print("="*70)

if __name__ == "__main__":
    # è®¾ç½®éšæœºç§å­ä»¥ä¿è¯å¯é‡å¤æ€§
    random.seed(42)

    augment_training_data(
        input_file="data/train/mixed_dataset.jsonl",
        output_file="data/train/mixed_dataset_augmented.jsonl",
        target_code_ratio=0.10,  # ç›®æ ‡10% Codeæ ·æœ¬
        add_humaneval=True  # æ·»åŠ HumanEvalæ•°æ®
    )
