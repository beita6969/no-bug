#!/usr/bin/env python3
"""
éªŒè¯æœ€ç»ˆæ•°æ®é›†åˆ†å¸ƒ
"""

import json
from pathlib import Path
from collections import defaultdict

# æ•°æ®ç›®å½•
data_dir = Path('/home/yijia/.claude/11/integrated_aflow_roll/data')
mixed_dir = data_dir / 'mixed'

def analyze_dataset(filename):
    """åˆ†ææ•°æ®é›†"""
    file_path = mixed_dir / filename

    if not file_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return None

    print(f"\nğŸ“Š åˆ†æ {filename}")
    print("="*60)

    # ç»Ÿè®¡
    total = 0
    type_counts = defaultdict(int)
    source_counts = defaultdict(int)

    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                sample = json.loads(line)
                total += 1

                # ç±»å‹ç»Ÿè®¡
                ptype = sample.get('problem_type', 'unknown')
                type_counts[ptype] += 1

                # æ•°æ®æºç»Ÿè®¡
                source = sample.get('source', 'unknown')
                source_counts[source] += 1

    print(f"æ€»æ ·æœ¬æ•°: {total:,}")

    # æŒ‰ç±»å‹åˆ†å¸ƒ
    print("\næŒ‰ç±»å‹åˆ†å¸ƒ:")
    for ptype in sorted(type_counts.keys()):
        count = type_counts[ptype]
        percentage = count / total * 100 if total > 0 else 0
        print(f"  {ptype:10s}: {count:6,} ({percentage:5.1f}%)")

    # æŒ‰æ•°æ®æºåˆ†å¸ƒ
    print("\næŒ‰æ•°æ®æºåˆ†å¸ƒ:")
    for source in sorted(source_counts.keys(), key=lambda x: source_counts[x], reverse=True):
        count = source_counts[source]
        percentage = count / total * 100 if total > 0 else 0
        print(f"  {source:15s}: {count:6,} ({percentage:5.1f}%)")

    return {
        'total': total,
        'type_counts': dict(type_counts),
        'source_counts': dict(source_counts)
    }

def main():
    print("="*60)
    print("ğŸ” éªŒè¯æœ€ç»ˆæ•°æ®é›†åˆ†å¸ƒ")
    print("="*60)

    # åˆ†ææ‰€æœ‰ç›¸å…³æ•°æ®é›†
    datasets = [
        'train_mixed_with_math.jsonl',  # æœ€æ–°çš„åŒ…å«MATHçš„æ•°æ®é›†
        'train_mixed_balanced.jsonl',   # ä¹‹å‰çš„å¹³è¡¡æ•°æ®é›†
        'train_mixed.jsonl',            # åŸå§‹è®­ç»ƒé›†
    ]

    results = {}

    for dataset_name in datasets:
        result = analyze_dataset(dataset_name)
        if result:
            results[dataset_name] = result

    # æ¯”è¾ƒç»“æœ
    if 'train_mixed_with_math.jsonl' in results and 'train_mixed_balanced.jsonl' in results:
        print("\n" + "="*60)
        print("ğŸ“ˆ å¯¹æ¯”åˆ†æ: train_mixed_with_math vs train_mixed_balanced")
        print("="*60)

        math_data = results['train_mixed_with_math.jsonl']
        balanced_data = results['train_mixed_balanced.jsonl']

        print(f"\næ ·æœ¬æ•°å˜åŒ–: {balanced_data['total']:,} â†’ {math_data['total']:,} (+{math_data['total'] - balanced_data['total']:,})")

        print("\nç±»å‹åˆ†å¸ƒå˜åŒ–:")
        all_types = set(math_data['type_counts'].keys()) | set(balanced_data['type_counts'].keys())
        for ptype in sorted(all_types):
            old_count = balanced_data['type_counts'].get(ptype, 0)
            new_count = math_data['type_counts'].get(ptype, 0)
            change = new_count - old_count
            old_pct = old_count / balanced_data['total'] * 100 if balanced_data['total'] > 0 else 0
            new_pct = new_count / math_data['total'] * 100 if math_data['total'] > 0 else 0

            change_str = f"+{change:,}" if change > 0 else f"{change:,}"
            print(f"  {ptype:10s}: {old_pct:5.1f}% â†’ {new_pct:5.1f}% ({change_str} æ ·æœ¬)")

        print("\næ•°æ®æºå˜åŒ–:")
        # åªæ˜¾ç¤ºMATHç›¸å…³çš„å˜åŒ–
        if 'MATH' in math_data['source_counts']:
            math_count = math_data['source_counts']['MATH']
            print(f"  MATH: 0 â†’ {math_count:,} (+{math_count:,} æ ·æœ¬)")

    # æ¨èä½¿ç”¨å“ªä¸ªæ•°æ®é›†
    print("\n" + "="*60)
    print("âœ… æ¨èä½¿ç”¨: train_mixed_with_math.jsonl")
    print("   åŸå› : åŒ…å«äº†MATHæ•°æ®é›†çš„é«˜è´¨é‡æ•°å­¦é¢˜ç›®")
    print("="*60)

if __name__ == '__main__':
    main()
