#!/usr/bin/env python3
"""
åˆ†æmixedæ•°æ®é›†çš„è¯¦ç»†åˆ†å¸ƒ
"""

import json
from collections import defaultdict
from pathlib import Path

data_dir = Path('/home/yijia/.claude/11/integrated_aflow_roll/data/mixed')

def analyze_dataset(file_path, dataset_name):
    """åˆ†æå•ä¸ªæ•°æ®é›†"""
    type_counts = defaultdict(int)
    source_counts = defaultdict(int)
    source_type_counts = defaultdict(lambda: defaultdict(int))

    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                sample = json.loads(line)
                problem_type = sample.get('problem_type', 'unknown')
                source = sample.get('source', 'unknown')

                type_counts[problem_type] += 1
                source_counts[source] += 1
                source_type_counts[source][problem_type] += 1

    total = sum(type_counts.values())

    print(f"\n{'='*60}")
    print(f"ğŸ“Š {dataset_name} æ•°æ®é›†åˆ†æ")
    print(f"{'='*60}")
    print(f"\næ€»æ ·æœ¬æ•°: {total:,}\n")

    print("æŒ‰é—®é¢˜ç±»å‹åˆ†å¸ƒ:")
    print("-" * 40)
    for ptype, count in sorted(type_counts.items(), key=lambda x: x[1], reverse=True):
        percentage = count / total * 100
        print(f"  {ptype:10} : {count:6,} ({percentage:6.2f}%)")

    print("\næŒ‰æ•°æ®æºåˆ†å¸ƒ:")
    print("-" * 40)
    for source, count in sorted(source_counts.items(), key=lambda x: x[1], reverse=True):
        percentage = count / total * 100
        print(f"  {source:15} : {count:6,} ({percentage:6.2f}%)")

    print("\nè¯¦ç»†åˆ†å¸ƒ (æ•°æ®æº Ã— é—®é¢˜ç±»å‹):")
    print("-" * 40)
    for source in sorted(source_counts.keys()):
        print(f"\n  {source}:")
        for ptype, count in sorted(source_type_counts[source].items()):
            percentage = count / total * 100
            print(f"    {ptype:10} : {count:6,} ({percentage:6.2f}%)")

    return {
        'total': total,
        'type_counts': dict(type_counts),
        'source_counts': dict(source_counts),
        'source_type_counts': {s: dict(t) for s, t in source_type_counts.items()}
    }

# ä¸»ç¨‹åº
print("="*60)
print("ğŸ¯ Mixed æ•°æ®é›†å®Œæ•´åˆ†ææŠ¥å‘Š")
print("="*60)

# åˆ†æè®­ç»ƒé›†
train_stats = analyze_dataset(data_dir / 'train_mixed.jsonl', 'è®­ç»ƒé›† (train_mixed.jsonl)')

# åˆ†ææµ‹è¯•é›†ï¼ˆåŸéªŒè¯é›†ï¼‰
test_stats = analyze_dataset(data_dir / 'test_mixed.jsonl', 'æµ‹è¯•é›† (test_mixed.jsonlï¼ŒåŸval_mixed.jsonl)')

# æ€»ç»“
print("\n" + "="*60)
print("ğŸ“ˆ æ•°æ®é›†æ€»ç»“")
print("="*60)

total_samples = train_stats['total'] + test_stats['total']
print(f"\næ€»æ ·æœ¬æ•°: {total_samples:,}")
print(f"  - è®­ç»ƒé›†: {train_stats['total']:,} ({train_stats['total']/total_samples*100:.1f}%)")
print(f"  - æµ‹è¯•é›†: {test_stats['total']:,} ({test_stats['total']/total_samples*100:.1f}%)")

# è®¡ç®—æ¯”ä¾‹
print("\né—®é¢˜ç±»å‹æ¯”ä¾‹å¯¹æ¯”:")
print("-" * 40)
print(f"{'ç±»å‹':10} {'è®­ç»ƒé›†':>15} {'æµ‹è¯•é›†':>15}")
print("-" * 40)

for ptype in ['math', 'code', 'qa', 'mixed']:
    train_count = train_stats['type_counts'].get(ptype, 0)
    test_count = test_stats['type_counts'].get(ptype, 0)
    train_pct = train_count / train_stats['total'] * 100 if train_stats['total'] > 0 else 0
    test_pct = test_count / test_stats['total'] * 100 if test_stats['total'] > 0 else 0
    print(f"{ptype:10} {train_count:6,} ({train_pct:5.1f}%) {test_count:6,} ({test_pct:5.1f}%)")

print("\n" + "="*60)
print("âœ… åˆ†æå®Œæˆï¼")
print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
print("  1. è®­ç»ƒé›†: data/mixed/train_mixed.jsonl")
print("  2. æµ‹è¯•é›†: data/mixed/test_mixed.jsonlï¼ˆå·²ä»val_mixed.jsonlå¤åˆ¶ï¼‰")
print("  3. è®­ç»ƒé›†åé‡QAå’ŒMixedç±»å‹ï¼ŒCodeæ ·æœ¬è¾ƒå°‘")
print("  4. æµ‹è¯•é›†ä¸­Codeæ ·æœ¬æ¯”ä¾‹è¾ƒé«˜ï¼Œå¯ä»¥å¾ˆå¥½åœ°è¯„ä¼°Codeèƒ½åŠ›")
print("="*60)
