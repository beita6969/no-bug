#!/usr/bin/env python3
"""æµ‹è¯•æœ¬åœ°LLM APIé€Ÿåº¦"""

import time
import requests
import json

API_URL = "http://127.0.0.1:8000/v1/chat/completions"

# æµ‹è¯•è¯·æ±‚ï¼ˆç±»ä¼¼operatorè°ƒç”¨ï¼‰
test_request = {
    "model": "qwen2.5-7b-local",
    "messages": [
        {
            "role": "system",
            "content": "You are a helpful math tutor."
        },
        {
            "role": "user",
            "content": "Solve: What is 25 * 4?"
        }
    ],
    "temperature": 0,
    "max_tokens": 512
}

print("ğŸ§ª æµ‹è¯•æœ¬åœ°LLM APIé€Ÿåº¦\n")
print("="*60)

# çƒ­èº«ï¼ˆç¬¬ä¸€æ¬¡è°ƒç”¨é€šå¸¸è¾ƒæ…¢ï¼‰
print("ğŸ”¥ çƒ­èº«è°ƒç”¨...")
response = requests.post(API_URL, json=test_request, timeout=60)
result = response.json()
print(f"  ç»“æœ: {result['choices'][0]['message']['content'][:100]}...")
print()

# æ­£å¼æµ‹è¯•ï¼ˆ3æ¬¡ï¼‰
times = []
for i in range(3):
    print(f"â±ï¸  æµ‹è¯• {i+1}/3...")
    start = time.time()
    response = requests.post(API_URL, json=test_request, timeout=60)
    elapsed = time.time() - start

    result = response.json()
    tokens = result['usage']['completion_tokens']
    tokens_per_sec = tokens / elapsed

    times.append(elapsed)

    print(f"  è€—æ—¶: {elapsed:.2f}ç§’")
    print(f"  Tokenæ•°: {tokens}")
    print(f"  é€Ÿåº¦: {tokens_per_sec:.1f} tokens/s")
    print()

print("="*60)
print("ğŸ“Š ç»Ÿè®¡ç»“æœ:")
print(f"  å¹³å‡è€—æ—¶: {sum(times)/len(times):.2f}ç§’")
print(f"  æœ€å¿«: {min(times):.2f}ç§’")
print(f"  æœ€æ…¢: {max(times):.2f}ç§’")
print()

# å¯¹æ¯”OpenAI API
print("ğŸ’¡ é¢„æœŸåŠ é€Ÿæ•ˆæœ:")
print(f"  OpenAI API (ç½‘ç»œå»¶è¿Ÿ): ~1-2ç§’ + æ¨ç†æ—¶é—´")
print(f"  æœ¬åœ°API (æ— ç½‘ç»œå»¶è¿Ÿ): {sum(times)/len(times):.2f}ç§’")
print(f"  åŠ é€Ÿæ¯”: ~{2 / (sum(times)/len(times)):.1f}x - {1 / (sum(times)/len(times)):.1f}x")
print("="*60)
