#!/usr/bin/env python3
"""
å®æ—¶è®­ç»ƒç›‘æ§å™¨ - æ˜¾ç¤ºå…³é”®æŒ‡æ ‡å’Œé”™è¯¯
"""
import time
import re
import sys
from collections import defaultdict

def parse_log_line(line):
    """è§£ææ—¥å¿—è¡Œæå–å…³é”®ä¿¡æ¯"""
    info = {}

    # Stepä¿¡æ¯
    if 'Step' in line and '/500' in line:
        match = re.search(r'Step (\d+)/(\d+)', line)
        if match:
            info['step'] = int(match.group(1))

    # å‡†ç¡®ç‡
    if 'å‡†ç¡®ç‡ç»Ÿè®¡:' in line:
        match = re.search(r'(\d+)/(\d+) = ([\d.]+)%', line)
        if match:
            info['correct'] = int(match.group(1))
            info['total'] = int(match.group(2))
            info['accuracy'] = float(match.group(3))

    # æ­£ç¡®æ€§è¯„åˆ†
    if 'å¹³å‡æ­£ç¡®æ€§è¯„åˆ†:' in line:
        match = re.search(r'å¹³å‡æ­£ç¡®æ€§è¯„åˆ†: ([\d.]+)/10\.0', line)
        if match:
            info['avg_score'] = float(match.group(1))

    # é—®é¢˜ç±»å‹åˆ†å¸ƒ
    if 'math:' in line and 'avg:' in line:
        match = re.search(r'(\w+): ([\d.]+)% \(avg: ([\d.-]+), n=(\d+)\)', line)
        if match:
            info['task_type'] = match.group(1)
            info['task_accuracy'] = float(match.group(2))
            info['task_avg_score'] = float(match.group(3))
            info['task_count'] = int(match.group(4))

    # é”™è¯¯
    if 'âŒ Workflowæ‰§è¡Œå¼‚å¸¸:' in line:
        match = re.search(r'âŒ Workflowæ‰§è¡Œå¼‚å¸¸: (\w+)', line)
        if match:
            info['error_type'] = match.group(1)

    # Fallback
    if 'âœ… FallbackæˆåŠŸ' in line:
        info['fallback'] = True

    # æ­£ç¡®æ€§è¯„åˆ†è¯¦æƒ…
    if 'æ­£ç¡®æ€§è¯„åˆ†:' in line and '|' in line:
        match = re.search(r'æ­£ç¡®æ€§è¯„åˆ†: ([\d.-]+)/10\.0', line)
        if match:
            info['sample_score'] = float(match.group(1))

    return info

def monitor_training(log_file):
    """å®æ—¶ç›‘æ§è®­ç»ƒæ—¥å¿—"""
    print("ğŸ” å¼€å§‹ç›‘æ§è®­ç»ƒ...")
    print("=" * 80)

    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'step': 0,
        'samples_processed': 0,
        'errors': defaultdict(int),
        'fallbacks': 0,
        'task_stats': defaultdict(lambda: {'correct': 0, 'total': 0, 'scores': []})
    }

    # æ‰“å¼€æ—¥å¿—æ–‡ä»¶
    with open(log_file, 'r') as f:
        # è·³åˆ°æ–‡ä»¶æœ«å°¾
        f.seek(0, 2)

        last_update = time.time()

        while True:
            line = f.readline()
            if not line:
                # æ²¡æœ‰æ–°å†…å®¹ï¼Œç­‰å¾…
                time.sleep(0.5)

                # æ¯5ç§’æ˜¾ç¤ºä¸€æ¬¡æ±‡æ€»
                if time.time() - last_update > 5:
                    print_summary(stats)
                    last_update = time.time()
                continue

            # è§£æè¡Œ
            info = parse_log_line(line)

            if 'step' in info:
                stats['step'] = info['step']
                print(f"\n{'='*80}")
                print(f"ğŸ“ Step {info['step']}/500")
                print(f"{'='*80}")

            if 'accuracy' in info:
                print(f"\nâœ… å‡†ç¡®ç‡: {info['correct']}/{info['total']} = {info['accuracy']:.1f}%")
                if 'avg_score' in info:
                    print(f"   å¹³å‡è¯„åˆ†: {info['avg_score']:.2f}/10.0")
                stats['samples_processed'] = info['total']

            if 'task_type' in info:
                task = info['task_type']
                print(f"   {task}: {info['task_accuracy']:.1f}% (avg: {info['task_avg_score']:.2f}, n={info['task_count']})")
                stats['task_stats'][task]['total'] = info['task_count']
                stats['task_stats'][task]['accuracy'] = info['task_accuracy']
                stats['task_stats'][task]['avg_score'] = info['task_avg_score']

            if 'error_type' in info:
                error_type = info['error_type']
                stats['errors'][error_type] += 1
                print(f"âŒ é”™è¯¯: {error_type} (ç´¯è®¡: {stats['errors'][error_type]}æ¬¡)")

            if 'fallback' in info:
                stats['fallbacks'] += 1
                print(f"ğŸ”„ Fallbackè§¦å‘ (ç´¯è®¡: {stats['fallbacks']}æ¬¡)")

            if 'sample_score' in info:
                score = info['sample_score']
                if score >= 8:
                    emoji = "ğŸŸ¢"
                elif score >= 5:
                    emoji = "ğŸŸ¡"
                elif score >= 0:
                    emoji = "ğŸŸ "
                else:
                    emoji = "ğŸ”´"
                print(f"{emoji} æ ·æœ¬å¾—åˆ†: {score:.1f}/10.0", end=' ')

def print_summary(stats):
    """æ‰“å°æ±‡æ€»ä¿¡æ¯"""
    print(f"\n{'â”€'*80}")
    print(f"ğŸ“Š è®­ç»ƒæ±‡æ€» (Step {stats['step']}/500)")
    print(f"   å·²å¤„ç†æ ·æœ¬: {stats['samples_processed']}")
    print(f"   ç´¯è®¡é”™è¯¯: {sum(stats['errors'].values())}æ¬¡")
    if stats['errors']:
        print(f"   é”™è¯¯åˆ†å¸ƒ: {dict(stats['errors'])}")
    print(f"   Fallbackæ¬¡æ•°: {stats['fallbacks']}æ¬¡")
    if stats['task_stats']:
        print(f"   ä»»åŠ¡ç±»å‹:")
        for task, data in stats['task_stats'].items():
            if data['total'] > 0:
                print(f"      {task}: {data.get('accuracy', 0):.1f}% (avg: {data.get('avg_score', 0):.2f})")
    print(f"{'â”€'*80}")

if __name__ == '__main__':
    import glob

    # æ‰¾åˆ°æœ€æ–°çš„æ—¥å¿—æ–‡ä»¶
    log_files = sorted(glob.glob('logs/train_restart_*.log'), reverse=True)
    if not log_files:
        print("âŒ æ‰¾ä¸åˆ°è®­ç»ƒæ—¥å¿—æ–‡ä»¶")
        sys.exit(1)

    log_file = log_files[0]
    print(f"ğŸ“„ ç›‘æ§æ—¥å¿—: {log_file}")

    try:
        monitor_training(log_file)
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  ç›‘æ§å·²åœæ­¢")
        sys.exit(0)
