#!/usr/bin/env python3
"""
AFlow + ROLL æ•°æ®æ¸…æ´—ä¸æ ¼å¼åŒ–å·¥å…· (Final Polish)

ç›®æ ‡:
1. ç»Ÿä¸€æ•°æ®æ ¼å¼ï¼Œé€‚é…è®­ç»ƒä»£ç  (problem, problem_type, ground_truth, ç­‰)
2. ä¸º LLM-as-a-Judge å‡†å¤‡è¾…åŠ©å­—æ®µ (ä¾‹å¦‚: æå–ç®€çŸ­ç­”æ¡ˆ, è§„èŒƒåŒ–ç±»å‹)
3. ä¿®å¤æ½œåœ¨çš„æ•°æ®è´¨é‡é—®é¢˜ (ç©ºå€¼, æ ¼å¼é”™è¯¯)
4. ç”Ÿæˆå¯ç›´æ¥ç”¨äºè®­ç»ƒçš„æœ€ç»ˆ JSONL æ–‡ä»¶

è¾“å‡ºæ ¼å¼:
{
    "problem": "...",
    "problem_type": "math" | "qa" | "code",
    "ground_truth": "...",
    "source": "...",
    "difficulty": "easy" | "hard",
    "meta": {
        "short_answer": "...",  # ç”¨äºå¿«é€Ÿè¯„ä¼° (Regex/Exact Match)
        "test_cases": "...",    # ç”¨äº Code æ‰§è¡Œæµ‹è¯•
        "context": "..."        # QA å¯èƒ½ä¼šç”¨åˆ°çš„ä¸Šä¸‹æ–‡
    }
}
"""

import json
import os
import re
from tqdm import tqdm

# é…ç½®
INPUT_DIR = "11/integrated_aflow_roll/data/final_mix"
OUTPUT_DIR = "11/integrated_aflow_roll/data/ready_to_train"
OS_ENV_PROXY = True # æ˜¯å¦ä½¿ç”¨ä»£ç† (æœ¬è„šæœ¬ä¸éœ€è¦ï¼Œä½†åœ¨æœåŠ¡å™¨ä¸Šå¯èƒ½éœ€è¦)

def ensure_dir(path):
    if not os.path.exists(path):
        os.makedirs(path)

def extract_short_answer(ground_truth, problem_type):
    """
    å°è¯•ä» ground_truth ä¸­æå–ç®€çŸ­ç­”æ¡ˆï¼Œç”¨äºè‡ªåŠ¨åŒ–è¯„ä¼°
    """
    if not ground_truth:
        return ""
    
    gt_str = str(ground_truth)
    
    if problem_type == "math":
        # å°è¯•æå– \boxed{} ä¸­çš„å†…å®¹ (MATH æ•°æ®é›†å¸¸ç”¨)
        boxed = re.findall(r"\\boxed\{(.*?)\}", gt_str)
        if boxed:
            return boxed[-1] # é€šå¸¸æœ€åä¸€ä¸ª boxed æ˜¯æœ€ç»ˆç­”æ¡ˆ
        
        # GSM8K é€šå¸¸æ˜¯ #### åé¢è·Ÿæ•°å­—
        hash_split = gt_str.split("####")
        if len(hash_split) > 1:
            return hash_split[-1].strip()
            
        return gt_str # å¦‚æœéƒ½æå–ä¸åˆ°ï¼Œè¿”å›åŸå€¼
        
    elif problem_type == "qa":
        # QA é€šå¸¸ ground_truth æ¯”è¾ƒçŸ­ï¼Œæˆ–è€…ç›´æ¥å°±æ˜¯ç­”æ¡ˆ
        return gt_str
        
    elif problem_type == "code":
        # Code çš„ "ç­”æ¡ˆ" é€šå¸¸æ˜¯å®Œæ•´ä»£ç ï¼Œå¾ˆéš¾æå– "ç®€çŸ­ç­”æ¡ˆ"
        # è¿™é‡Œæˆ‘ä»¬å¯èƒ½ä¸éœ€è¦ short_answerï¼Œå› ä¸º Code æœ‰ test cases
        return ""
        
    return gt_str

def clean_item(item):
    """
    æ¸…æ´—å•æ¡æ•°æ®
    """
    # 1. åŸºç¡€å­—æ®µæ£€æŸ¥
    if "problem" not in item or not item["problem"]:
        return None # ä¸¢å¼ƒæ— é—®é¢˜çš„æ•°æ®
        
    if "ground_truth" not in item or not item["ground_truth"]:
        # Code æ•°æ®é›†å¯èƒ½ç”¨ 'canonical_solution' æˆ– 'code'
        # ä½†ä¹‹å‰çš„è„šæœ¬åº”è¯¥å·²ç»ç»Ÿä¸€ä¸º ground_truth
        # å¦‚æœè¿˜æ˜¯ç©ºçš„ï¼Œå°è¯•æŒ½æ•‘
        return None

    # 2. ç±»å‹è§„èŒƒåŒ–
    p_type = item.get("problem_type", "unknown").lower()
    if p_type not in ["math", "qa", "code"]:
        p_type = "qa" # é»˜è®¤ä¸º QA
        
    # 3. å…ƒæ•°æ®æå–
    meta = item.get("meta", {})
    
    # æå–ç®€çŸ­ç­”æ¡ˆ (è¾…åŠ© Judge)
    short_ans = extract_short_answer(item["ground_truth"], p_type)
    if short_ans:
        meta["short_answer"] = short_ans
        
    # å¤„ç† Code ç‰¹æœ‰çš„ Test Cases
    if p_type == "code":
        # ä¹‹å‰çš„è„šæœ¬å¯èƒ½æŠŠ test æ”¾åœ¨äº†é¡¶å±‚å­—æ®µ
        test_cases = item.get("test", "") or item.get("test_list", "")
        if test_cases:
            if isinstance(test_cases, list):
                test_cases = "\n".join(test_cases)
            meta["test_cases"] = test_cases
            
        # ç¡®ä¿ entry_point å­˜åœ¨
        entry_point = item.get("entry_point", "")
        if entry_point:
            meta["entry_point"] = entry_point

    # 4. æ„å»ºæœ€ç»ˆå¯¹è±¡
    cleaned_item = {
        "problem": item["problem"].strip(),
        "problem_type": p_type,
        "ground_truth": str(item["ground_truth"]).strip(),
        "source": item.get("source", "unknown"),
        "difficulty": item.get("difficulty", "unknown"),
        "meta": meta
    }
    
    return cleaned_item

def process_file(input_filename, output_filename):
    input_path = os.path.join(INPUT_DIR, input_filename)
    output_path = os.path.join(OUTPUT_DIR, output_filename)
    
    print(f"ğŸ”„ å¤„ç†: {input_filename} -> {output_filename}")
    
    if not os.path.exists(input_path):
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ {input_path}")
        return
    
    valid_count = 0
    total_count = 0
    
    with open(input_path, 'r') as fin, open(output_path, 'w') as fout:
        for line in tqdm(fin):
            total_count += 1
            try:
                item = json.loads(line)
                cleaned = clean_item(item)
                if cleaned:
                    fout.write(json.dumps(cleaned) + "\n")
                    valid_count += 1
            except json.JSONDecodeError:
                continue
                
    print(f"âœ… å®Œæˆ: {valid_count}/{total_count} æ¡æ•°æ®æœ‰æ•ˆ")

def main():
    ensure_dir(OUTPUT_DIR)
    
    # å¤„ç†è®­ç»ƒé›†
    process_file("train_2k.jsonl", "train.jsonl")
    
    # å¤„ç†æµ‹è¯•é›†
    process_file("test_100.jsonl", "test.jsonl")
    
    print(f"\nğŸ‰ æ‰€æœ‰æ•°æ®å¤„ç†å®Œæˆï¼ä¿å­˜ç›®å½•: {OUTPUT_DIR}")
    print(f"ğŸ’¡ å»ºè®®æ›´æ–° config/training.yaml:")
    print(f'   train_dataset: "{os.path.join(OUTPUT_DIR, "train.jsonl")}"')
    print(f'   test_dataset: "{os.path.join(OUTPUT_DIR, "test.jsonl")}"')

if __name__ == "__main__":
    main()


