# LLM Judge ä¼˜åŒ–å®æ–½æŒ‡å—

> **æ–‡æ¡£ç‰ˆæœ¬**: 1.0
> **åˆ›å»ºæ—¥æœŸ**: 2025-11-23
> **ç›®æ ‡**: ä¸ºä¸åŒæ•°æ®é›†è®¾è®¡ä¸“å±çš„LLM Judgeï¼Œå‡å°‘è¯¯åˆ¤ï¼Œæå‡å‡†ç¡®ç‡

---

## ğŸ“‹ ç›®å½•

1. [èƒŒæ™¯å’ŒåŠ¨æœº](#èƒŒæ™¯å’ŒåŠ¨æœº)
2. [å½“å‰é—®é¢˜åˆ†æ](#å½“å‰é—®é¢˜åˆ†æ)
3. [è®¾è®¡æ–¹æ¡ˆ](#è®¾è®¡æ–¹æ¡ˆ)
4. [é…ç½®æ–‡ä»¶è¯´æ˜](#é…ç½®æ–‡ä»¶è¯´æ˜)
5. [å®æ–½æ­¥éª¤](#å®æ–½æ­¥éª¤)
6. [æµ‹è¯•å’ŒéªŒè¯](#æµ‹è¯•å’ŒéªŒè¯)
7. [é¢„æœŸæ•ˆæœ](#é¢„æœŸæ•ˆæœ)
8. [FAQ](#faq)

---

## èƒŒæ™¯å’ŒåŠ¨æœº

### å½“å‰çŠ¶æ€

**è®­ç»ƒæ—¥å¿—åˆ†æç»“æœ** (åŸºäº `logs/train_restored_v10.log`):
- æ€»æ ·æœ¬: 848
- å½“å‰å‡†ç¡®ç‡: **64.9%**
- è¯¯åˆ¤ç‡: **12-20%** (35-60ä¸ªæ ·æœ¬)
- ä¸»è¦é—®é¢˜:
  1. **æ ¼å¼é—®é¢˜** (30-50ä¸ªæ ·æœ¬): ä»£ç æ³„æ¼ã€ç©ºè¾“å‡ºã€å•ä½å·®å¼‚
  2. **æ ‡æ³¨æ­§ä¹‰** (5-10ä¸ªæ ·æœ¬): Drawstring bagç­‰ä¸»è§‚æ€§é—®é¢˜
  3. **Judgeæ¨æ–­é”™è¯¯** (æœªçŸ¥æ•°é‡): é€‰é¡¹é¢˜çš„"è„‘è¡¥"ç­‰ä»·æ€§

### ä¼˜åŒ–ç›®æ ‡

- å°†è¯¯åˆ¤ç‡ä» **12-20%** é™è‡³ **< 5%**
- å°†å‡†ç¡®ç‡ä» **64.9%** æå‡è‡³ **70-75%**
- ä¸ºæ¯ç§æ•°æ®é›†æä¾›é’ˆå¯¹æ€§çš„è¯„ä¼°ç­–ç•¥

---

## å½“å‰é—®é¢˜åˆ†æ

### é—®é¢˜1: ä¸€åˆ€åˆ‡çš„è¯„ä¼°ç­–ç•¥

**å½“å‰å®ç°** (`src/reward_computer.py:114-308`):
- ä½¿ç”¨**å•ä¸€çš„é€šç”¨LLM Judge**å¤„ç†æ‰€æœ‰ç±»å‹é—®é¢˜
- åŒä¸€ä¸ªpromptæ¨¡æ¿é€‚ç”¨äºMathã€Codeã€QA

**é—®é¢˜**:
```python
# å½“å‰çš„é€šç”¨promptï¼ˆç®€åŒ–ç‰ˆï¼‰
query_prompt = """
You are a precise mathematical and logical equivalence evaluator.

**Step 1**: Extract the Final Answer from both prediction and ground truth
**Step 2**: Normalize Both Answers
**Step 3**: Compare Equivalence

Prediction: {prediction}
Ground Truth: {ground_truth}
"""
```

è¿™ä¸ªpromptå¯¹äºä¸åŒç±»å‹çš„é—®é¢˜å­˜åœ¨ä»¥ä¸‹å±€é™ï¼š

| æ•°æ®é›†ç±»å‹ | é—®é¢˜ | ç¤ºä¾‹ |
|-----------|------|------|
| **GSM8K** | æœªè¯†åˆ« `####` æ ¼å¼ | `#### 72` è¢«å½“ä½œæ™®é€šæ–‡æœ¬ |
| **Math** | æœªä¼˜å…ˆä½¿ç”¨ `meta.short_answer` | ä»é•¿æ–‡æœ¬ä¸­æå–ç­”æ¡ˆå¯èƒ½å‡ºé”™ |
| **Code** | ä½¿ç”¨æ–‡æœ¬åŒ¹é…è€Œéæ‰§è¡Œ | å˜é‡åä¸åŒè¢«åˆ¤é”™ |
| **QA** | æ¨æ–­é€‰é¡¹ç­‰ä»·æ€§ | `"E"` â‰  `"might dream"` è¢«åˆ¤ä¸ºç­‰ä»· |

### é—®é¢˜2: æ ¼å¼æå–ä¸é²æ£’

**å…¸å‹æ¡ˆä¾‹**:
```python
# æ¨¡å‹è¾“å‡º
prediction = "\\boxed{def solve() -> int:\n    return 50}"

# Ground Truth
ground_truth = "50"

# å½“å‰Judgeè¯„åˆ†: 0.0 âŒ
# åº”è¯¥: æå–ä»£ç æ‰§è¡Œç»“æœæˆ–è¯†åˆ«ä¸ºæ ¼å¼é”™è¯¯
```

**æ ¹æœ¬åŸå› **:
- Answer Extractor (`src/answer_extractor.py`) æœªå¤„ç†ä»£ç æ³„æ¼
- Judgeæœªè¯†åˆ« `\\boxed{def ...}` æ˜¯å¼‚å¸¸æ ¼å¼

### é—®é¢˜3: é€‰é¡¹é¢˜çš„"è„‘è¡¥"é—®é¢˜

**è§‚å¯Ÿåˆ°çš„æ¨¡å¼**:

| æ¨¡å‹ç­”æ¡ˆ | Ground Truth | å½“å‰è¯„åˆ† | åº”è¯¥ | é—®é¢˜ |
|---------|-------------|---------|------|------|
| `"might dream"` | `"E"` | 1.0 âœ… | 1.0 âœ… | æ­£ç¡® |
| `"E"` | `"might dream"` | 1.0 âœ… | 0.0 âŒ | **è¯¯åˆ¤** |

**åˆ†æ**:
- ç¬¬ä¸€ç§æƒ…å†µï¼šæ¨¡å‹ï¿½ï¿½ï¿½å‡ºå®Œæ•´ç­”æ¡ˆï¼ŒJudgeæ¨æ–­è¿™æ˜¯Eé€‰é¡¹çš„å†…å®¹ â†’ åˆç†
- ç¬¬äºŒç§æƒ…å†µï¼šæ¨¡å‹åªç»™å‡ºå­—æ¯Eï¼ŒJudgeæ¨æ–­Eå¯¹åº”"might dream" â†’ **ä¸åˆç†**

**åŸå› **: Judgeçš„promptæœªæ˜ç¡®ç¦æ­¢è¿™ç§æ¨æ–­

---

## è®¾è®¡æ–¹æ¡ˆ

### æ ¸å¿ƒæ€æƒ³: æ•°æ®é›†ä¸“å±ç­–ç•¥

**è®¾è®¡åŸåˆ™**:
1. **é’ˆå¯¹æ€§**: æ¯ç§æ•°æ®é›†ä½¿ç”¨å®šåˆ¶åŒ–çš„è¯„ä¼°ç­–ç•¥
2. **ä¼˜å…ˆçº§**: æ˜ç¡®çš„è¯„ä¼°æ–¹æ³•é€‰æ‹©é¡ºåº
3. **é²æ£’æ€§**: å¤„ç†å„ç§è¾¹ç¼˜æƒ…å†µå’Œæ ¼å¼é—®é¢˜
4. **å¯æ‰©å±•**: æ˜“äºæ·»åŠ æ–°æ•°æ®é›†æ”¯æŒ

### æ¶æ„è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            GRPOTrainer.train_step()                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       RewardComputer.compute_reward()               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  1. è¯†åˆ«æ•°æ®é›†ç±»å‹ (source/problem_type)      â”‚  â”‚
â”‚  â”‚  2. é€‰æ‹©è¯„ä¼°ç­–ç•¥                              â”‚  â”‚
â”‚  â”‚  3. è°ƒç”¨å¯¹åº”çš„Judge                           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚             â”‚             â”‚              â”‚
     â†“             â†“             â†“              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GSM8K   â”‚  â”‚  Math    â”‚  â”‚  Code   â”‚  â”‚    QA    â”‚
â”‚ Judge   â”‚  â”‚  Judge   â”‚  â”‚  Exec   â”‚  â”‚  Judge   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚             â”‚             â”‚              â”‚
     â†“             â†“             â†“              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            é…ç½®æ–‡ä»¶: judge_prompts.yaml              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ - GSM8K: è¯†åˆ«####æ ¼å¼ï¼Œå¿½ç•¥<<calc>>          â”‚  â”‚
â”‚  â”‚ - Math: ä¼˜å…ˆshort_answerï¼ŒLaTeXæ ‡å‡†åŒ–       â”‚  â”‚
â”‚  â”‚ - Code: å®Œå…¨ä¾èµ–æµ‹è¯•æ‰§è¡Œ                      â”‚  â”‚
â”‚  â”‚ - QA: ç¦æ­¢æ¨æ–­é€‰é¡¹ç­‰ä»·æ€§                      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### è¯„ä¼°ç­–ç•¥å†³ç­–æ ‘

```python
def select_evaluation_strategy(sample: Dict) -> str:
    """æ ¹æ®æ ·æœ¬ç‰¹å¾é€‰æ‹©è¯„ä¼°ç­–ç•¥"""

    # ä¼˜å…ˆçº§1: æ£€æŸ¥sourceå­—æ®µ
    source = sample.get('source', '')

    if source in ['humaneval', 'mbpp']:
        # Codeé¢˜ï¼šä½¿ç”¨æµ‹è¯•æ‰§è¡Œ
        return 'test_execution'

    elif source == 'gsm8k':
        # GSM8Kï¼šä½¿ç”¨GSM8Kä¸“å±Judge
        return 'gsm8k_judge'

    elif source == 'math':
        # Mathï¼šä½¿ç”¨Mathä¸“å±Judge
        return 'math_judge'

    elif source in ['hotpotqa', 'squad_v2', 'commonsenseqa', 'mmlu']:
        # QAé¢˜ï¼šä½¿ç”¨QAä¸“å±Judge
        return f'{source}_judge'

    # ä¼˜å…ˆçº§2: æ ¹æ®problem_type
    problem_type = sample.get('problem_type', '')

    if problem_type == 'math':
        return 'math_judge'  # é»˜è®¤Math Judge
    elif problem_type == 'code':
        return 'test_execution'
    elif problem_type == 'qa':
        return 'qa_judge'  # é»˜è®¤QA Judge

    # ä¼˜å…ˆçº§3: é»˜è®¤ç­–ç•¥
    return 'default_judge'
```

---

## é…ç½®æ–‡ä»¶è¯´æ˜

### æ–‡ä»¶ä½ç½®

**ä¸»é…ç½®æ–‡ä»¶**: `config/judge_prompts.yaml`

### é…ç½®ç»“æ„

```yaml
# å…¨å±€é…ç½®
global:
  model: "gpt-oss-120b"
  temperature: 0.0
  max_tokens: 200

# å„æ•°æ®é›†é…ç½®
gsm8k:
  enabled: true
  answer_extraction: {...}
  judge_prompt: |...

math:
  enabled: true
  answer_extraction: {...}
  judge_prompt: |...

humaneval:
  enabled: false  # ä½¿ç”¨æµ‹è¯•æ‰§è¡Œ
  evaluation_method: "test_execution"

# ... å…¶ä»–æ•°æ®é›†

# æ•°æ®é›†æ˜ å°„
dataset_mapping:
  by_source:
    gsm8k: "gsm8k"
    math: "math"
    # ...
```

### å…³é”®é…ç½®é¡¹

#### 1. GSM8Ké…ç½®

**ç‰¹ç‚¹**:
- Ground truthæ ¼å¼: `ä¸­é—´æ­¥éª¤ <<calc>> ... #### æœ€ç»ˆç­”æ¡ˆ`
- éœ€è¦æå– `####` åçš„æ•°å­—

**é…ç½®**:
```yaml
gsm8k:
  answer_extraction:
    priority:
      - "#### åçš„æ•°å­—"  # æœ€é«˜ä¼˜å…ˆçº§
      - "\\boxed{}å†…å®¹"

    patterns:
      - regex: "####\\s*(-?\\d+\\.?\\d*)"
      - regex: "<<([^>]+>>"  # å¿½ç•¥ä¸­é—´è®¡ç®—
        action: "ignore"

  judge_prompt: |
    **Special Rules for GSM8K**:
    1. Ground truth ends with "#### ANSWER"
    2. Extract ONLY the number after "####"
    3. Ignore "<<calc>>" markers
```

#### 2. Mathé…ç½®

**ç‰¹ç‚¹**:
- Ground truthåŒ…å«LaTeX: `\\frac{1}{2}`, `\\boxed{}`
- æœ‰ `meta.short_answer` å­—æ®µï¼ˆæ ‡å‡†åŒ–ç­”æ¡ˆï¼‰

**é…ç½®**:
```yaml
math:
  answer_extraction:
    priority:
      - "meta.short_answerå­—æ®µ"  # ä¼˜å…ˆä½¿ç”¨ï¼
      - "\\boxed{}å†…å®¹"

    latex_normalization:
      enabled: true
      rules:
        - "\\frac{a}{b} â†’ a/b"
        - "\\sqrt{x} â†’ sqrt(x)"

  judge_prompt: |
    **Special Rules for MATH Dataset**:
    1. If meta.short_answer exists, use it as canonical answer
    2. Handle LaTeX: \\frac{1}{2} = 0.5
    3. Allow equivalent forms: 1/2 = 0.5 = 50%
```

#### 3. HumanEval/MBPPé…ç½®

**ç‰¹ç‚¹**:
- æœ‰æµ‹è¯•ç”¨ä¾‹
- åº”è¯¥æ‰§è¡Œä»£ç éªŒè¯ï¼Œä¸ç”¨LLM Judge

**é…ç½®**:
```yaml
humaneval:
  enabled: false  # ç¦ç”¨LLM Judgeï¼
  evaluation_method: "test_execution"

  test_execution:
    timeout: 5.0
    sandbox: true

  # ä»…åœ¨ç¼ºå°‘æµ‹è¯•ç”¨ä¾‹æ—¶fallbackåˆ°Judge
  fallback_judge_prompt: |
    âš ï¸ WARNING: Test cases missing, using semantic comparison.
    This is NOT reliable.
```

#### 4. QAé…ç½®ï¼ˆHotpotQA, SQuAD, CommonsenseQA, MMLUï¼‰

**ç‰¹ç‚¹**:
- å¤šé€‰é¢˜ï¼ˆABCDEé€‰é¡¹ï¼‰
- å®¹æ˜“å‡ºç°"æ¨æ–­"ç­‰ä»·æ€§çš„é—®é¢˜

**é…ç½®**:
```yaml
hotpotqa:
  judge_prompt: |
    ğŸš« **PROHIBITION #1: No Inference of Option Labels**
    - If Prediction="E" and Ground Truth="might dream":
      â†’ Judge as **False** (Do NOT assume E means "might dream")
    - If Prediction="might dream" and Ground Truth="E":
      â†’ Judge as **True** (Prediction matches option content)

    **Example**:
    Prediction: "E"
    Ground Truth: "might dream"
    â†’ **False** âœ… Correct judgment

commonsenseqa:
  multiple_choice:
    enabled: true
    option_format: "A-E"

  judge_prompt: |
    **Evaluation Logic**:

    Case 1: Both are letters (A-E)
      â†’ Simple comparison

    Case 2: Prediction is letter, Ground Truth is text
      â†’ **False** (ç¦æ­¢æ¨æ–­)

    Case 3: Prediction is text, Ground Truth is letter
      â†’ Check if text matches option content

    Case 4: Both are text
      â†’ Normalize and compare
```

---

## å®æ–½æ­¥éª¤

### é˜¶æ®µ0: å‡†å¤‡å·¥ä½œ âœ…

- [x] åˆ†æè®­ç»ƒæ—¥å¿—ï¼Œè¯†åˆ«è¯¯åˆ¤æ¨¡å¼
- [x] åˆ›å»ºè¯¯åˆ¤åˆ†ææŠ¥å‘Š (`docs/MISJUDGMENT_ANALYSIS.md`)
- [x] åˆ›å»ºè¯¦ç»†é”™è¯¯åˆ†ææŠ¥å‘Š (`docs/ERROR_PATTERNS_DETAILED.md`)
- [x] è®¾è®¡æ•°æ®é›†ä¸“å±Judgeé…ç½® (`config/judge_prompts.yaml`)

### é˜¶æ®µ1: æ ¸å¿ƒå®ç°ï¼ˆéœ€è¦ä»£ç ä¿®æ”¹ï¼‰â¸ï¸

> âš ï¸ **æ³¨æ„**: æ ¹æ®æ‚¨çš„è¦æ±‚ï¼Œä»£ç ä¿®æ”¹éƒ¨åˆ†æš‚åœã€‚ä»¥ä¸‹æ˜¯å®æ–½è®¡åˆ’ï¼Œå¾…æ‚¨ç¡®è®¤ç­–ç•¥åå†æ‰§è¡Œã€‚

#### 1.1 ä¿®æ”¹ RewardComputer

**æ–‡ä»¶**: `src/reward_computer.py`

**ä»»åŠ¡**:
1. æ·»åŠ é…ç½®åŠ è½½æ–¹æ³•
2. å®ç°æ•°æ®é›†è¯†åˆ«é€»è¾‘
3. æ ¹æ®æ•°æ®é›†é€‰æ‹©Judge prompt
4. ä¸ºæ¯ç§æ•°æ®é›†æ·»åŠ ä¸“é—¨çš„é¢„å¤„ç†

**ä¼ªä»£ç **:
```python
class RewardComputer:
    def __init__(self, ...):
        # åŠ è½½Judgeé…ç½®
        self.judge_config = self._load_judge_config()

    def _load_judge_config(self) -> Dict:
        """åŠ è½½judge_prompts.yamlé…ç½®"""
        with open('config/judge_prompts.yaml') as f:
            return yaml.safe_load(f)

    def _select_judge_prompt(self, sample: Dict) -> str:
        """æ ¹æ®æ ·æœ¬é€‰æ‹©Judge prompt"""
        source = sample.get('source', '')
        problem_type = sample.get('problem_type', '')

        # ä¼˜å…ˆçº§ï¼šsource > problem_type > default
        if source in self.judge_config['dataset_mapping']['by_source']:
            dataset = self.judge_config['dataset_mapping']['by_source'][source]
            return self.judge_config[dataset]['judge_prompt']

        # Fallback
        return self.judge_config['global']['output_format']

    def compute_reward(self, problem, prediction, ground_truth,
                      problem_type, metadata, test, entry_point):
        # 1. è¯†åˆ«æ•°æ®é›†
        dataset = self._identify_dataset(sample)

        # 2. é€‰æ‹©è¯„ä¼°ç­–ç•¥
        if dataset in ['humaneval', 'mbpp'] and test:
            # Code: ä½¿ç”¨æµ‹è¯•æ‰§è¡Œ
            return self._check_code_solution(...)

        elif dataset == 'gsm8k':
            # GSM8K: æå–####ç­”æ¡ˆ
            gt_extracted = self._extract_gsm8k_answer(ground_truth)
            pred_extracted = self._extract_answer(prediction)
            return self._llm_judge_compare(
                pred_extracted, gt_extracted,
                prompt_template=self.judge_config['gsm8k']['judge_prompt']
            )

        elif dataset == 'math':
            # Math: ä¼˜å…ˆä½¿ç”¨short_answer
            gt_answer = metadata.get('short_answer', ground_truth)
            return self._llm_judge_compare(
                prediction, gt_answer,
                prompt_template=self.judge_config['math']['judge_prompt']
            )

        # ... å…¶ä»–æ•°æ®é›†
```

#### 1.2 å¢å¼º Answer Extractor

**æ–‡ä»¶**: `src/answer_extractor.py`

**ä»»åŠ¡**:
1. è¯†åˆ«å¹¶å¤„ç†ä»£ç æ³„æ¼ (`\\boxed{def ...}`)
2. æå–GSM8Kçš„ `####` ç­”æ¡ˆ
3. å¤„ç†LaTeXæ ¼å¼
4. æ ‡å‡†åŒ–QAç­”æ¡ˆï¼ˆå°å†™ã€å»æ ‡ç‚¹ï¼‰

**ä¼ªä»£ç **:
```python
class AnswerExtractor:
    @staticmethod
    def extract_gsm8k_answer(text: str) -> str:
        """æå–GSM8Kçš„#### åç­”æ¡ˆ"""
        match = re.search(r'####\\s*(-?\\d+\\.?\\d*)', text)
        if match:
            return match.group(1)
        return text

    @staticmethod
    def extract_from_boxed(text: str) -> Optional[str]:
        """ä»\\boxed{}æå–ï¼Œå¤„ç†ç‰¹æ®Šæƒ…å†µ"""
        match = re.search(r'\\\\boxed\\{([^}]+)\\}', text)
        if match:
            content = match.group(1)

            # æ£€æŸ¥æ˜¯å¦æ˜¯ä»£ç æ³„æ¼
            if content.startswith('def ') or 'return ' in content:
                logger.warning("æ£€æµ‹åˆ°ä»£ç æ³„æ¼ï¼Œå°è¯•æå–æ‰§è¡Œç»“æœ")
                return None  # éœ€è¦é‡æ–°å¤„ç†

            # æ£€æŸ¥æ˜¯å¦æ˜¯é”™è¯¯ä¿¡æ¯
            if content.startswith('Error:'):
                logger.warning("æ£€æµ‹åˆ°é”™è¯¯ä¿¡æ¯")
                return None

            return content
        return None

    @staticmethod
    def normalize_latex(text: str) -> str:
        """æ ‡å‡†åŒ–LaTeXè¡¨è¾¾å¼"""
        # \\frac{a}{b} â†’ a/b
        text = re.sub(r'\\\\frac\\{([^}]+)\\}\\{([^}]+)\\}', r'(\\1)/(\\2)', text)
        # \\sqrt{x} â†’ sqrt(x)
        text = re.sub(r'\\\\sqrt\\{([^}]+)\\}', r'sqrt(\\1)', text)
        return text
```

#### 1.3 åˆ›å»ºæ•°æ®é›†éªŒè¯å™¨

**æ–°æ–‡ä»¶**: `src/dataset_validators.py`

**ä»»åŠ¡**:
ä¸ºæ¯ç§æ•°æ®é›†åˆ›å»ºä¸“é—¨çš„éªŒè¯å™¨ç±»

**ä¼ªä»£ç **:
```python
class GSM8KValidator:
    """GSM8Kæ•°æ®é›†éªŒè¯å™¨"""

    @staticmethod
    def validate_answer(prediction: str, ground_truth: str) -> bool:
        # 1. æå–#### åçš„æ•°å­—
        gt_number = AnswerExtractor.extract_gsm8k_answer(ground_truth)

        # 2. ä»é¢„æµ‹ä¸­æå–æ•°å­—
        pred_number = AnswerExtractor.extract_number(prediction)

        # 3. æ•°å€¼æ¯”è¾ƒ
        try:
            return abs(float(pred_number) - float(gt_number)) < 1e-4
        except ValueError:
            return False

class MathValidator:
    """Mathæ•°æ®é›†éªŒè¯å™¨"""

    @staticmethod
    def validate_answer(prediction: str, ground_truth: str,
                       short_answer: Optional[str] = None) -> bool:
        # 1. ä¼˜å…ˆä½¿ç”¨short_answer
        if short_answer:
            target = short_answer
        else:
            target = AnswerExtractor.extract_from_boxed(ground_truth)

        # 2. LaTeXæ ‡å‡†åŒ–
        pred_normalized = AnswerExtractor.normalize_latex(prediction)
        target_normalized = AnswerExtractor.normalize_latex(target)

        # 3. æ•°å­¦ç­‰ä»·æ€§åˆ¤æ–­
        return MathEquivalence.check(pred_normalized, target_normalized)

class QAValidator:
    """QAæ•°æ®é›†éªŒè¯å™¨"""

    @staticmethod
    def validate_answer(prediction: str, ground_truth: str) -> bool:
        # è§„åˆ™1: ç¦æ­¢é€‰é¡¹æ¨æ–­
        if len(prediction) == 1 and prediction.isalpha():
            # é¢„æµ‹æ˜¯å•å­—æ¯
            if len(ground_truth) > 1:
                # çœŸå€¼æ˜¯æ–‡æœ¬ â†’ False
                return False
            else:
                # çœŸå€¼ä¹Ÿæ˜¯å­—æ¯ â†’ ç›´æ¥æ¯”è¾ƒ
                return prediction.upper() == ground_truth.upper()

        # è§„åˆ™2: æ ‡å‡†åŒ–æ¯”è¾ƒ
        pred_norm = QAValidator.normalize(prediction)
        gt_norm = QAValidator.normalize(ground_truth)

        return pred_norm == gt_norm or pred_norm in gt_norm

    @staticmethod
    def normalize(text: str) -> str:
        # å°å†™
        text = text.lower()
        # ç§»é™¤å† è¯
        text = re.sub(r'\\b(a|an|the)\\b', '', text)
        # ç§»é™¤æ ‡ç‚¹
        text = re.sub(r'[^\\w\\s]', '', text)
        # å»ç©ºæ ¼
        return text.strip()
```

#### 1.4 ä¿®å¤éªŒè¯é›†é˜ˆå€¼Bug

**æ–‡ä»¶**: `src/grpo_trainer.py`
**è¡Œå·**: 737

**å½“å‰ä»£ç **:
```python
num_correct = sum(1 for score in correctness_scores if score >= 5.0)
```

**ä¿®å¤å**:
```python
num_correct = sum(1 for score in correctness_scores if score >= 0.9)
```

**å½±å“**: è¿™ä¸ªbugå¯¼è‡´éªŒè¯å‡†ç¡®ç‡ï¿½ï¿½ç›´æ˜¾ç¤ºä¸º0%ï¼Œä¿®å¤åå¯ä»¥çœ‹åˆ°çœŸå®çš„éªŒè¯æ€§èƒ½

### é˜¶æ®µ2: æµ‹è¯•å’ŒéªŒè¯

#### 2.1 å•å…ƒæµ‹è¯•

**åˆ›å»º**: `tests/test_dataset_judges.py`

```python
import pytest
from src.reward_computer import RewardComputer

class TestGSM8KJudge:
    def test_extract_final_answer(self):
        ground_truth = "Natalia sold 48/2 = <<48/2=24>>24...\\n#### 72"
        expected = "72"
        result = AnswerExtractor.extract_gsm8k_answer(ground_truth)
        assert result == expected

    def test_ignore_intermediate_calc(self):
        prediction = "24"
        ground_truth = "<<48/2=24>>...#### 72"
        # Should extract 72, not 24
        assert not GSM8KValidator.validate_answer(prediction, ground_truth)

class TestQAJudge:
    def test_prohibit_option_inference(self):
        """æµ‹è¯•ç¦æ­¢é€‰é¡¹æ¨æ–­"""
        prediction = "E"
        ground_truth = "might dream"
        # åº”è¯¥åˆ¤ä¸ºFalseï¼ˆç¦æ­¢æ¨æ–­E=might dreamï¼‰
        assert not QAValidator.validate_answer(prediction, ground_truth)

    def test_allow_text_match(self):
        """æµ‹è¯•å…è®¸æ–‡æœ¬åŒ¹é…"""
        prediction = "might dream"
        ground_truth = "E"
        # åº”è¯¥åˆ¤ä¸ºTrueï¼ˆæ–‡æœ¬åŒ¹é…é€‰é¡¹å†…å®¹ï¼‰
        assert QAValidator.validate_answer(prediction, ground_truth)
```

#### 2.2 é›†æˆæµ‹è¯•

**åˆ›å»º**: `tests/test_reward_computer_integration.py`

```python
class TestRewardComputerIntegration:
    @pytest.fixture
    def reward_computer(self):
        return RewardComputer(config_path='config/training.yaml')

    def test_gsm8k_sample(self, reward_computer):
        sample = {
            'problem': '...',
            'source': 'gsm8k',
            'problem_type': 'math'
        }
        prediction = "The answer is 72."
        ground_truth = "...#### 72"

        reward = reward_computer.compute_reward(
            problem=sample['problem'],
            prediction=prediction,
            ground_truth=ground_truth,
            problem_type='math',
            metadata={},
            test='',
            entry_point=''
        )

        assert reward == 1.0  # Should be correct

    # ... æ›´å¤šæµ‹è¯•
```

#### 2.3 å›å½’æµ‹è¯•

**ä½¿ç”¨å·²çŸ¥çš„è¯¯åˆ¤æ¡ˆä¾‹**:

```python
# tests/test_misjudgment_cases.py

MISJUDGMENT_CASES = [
    {
        'name': 'Drawstring Bag',
        'prediction': 'D. tied up',
        'ground_truth': 'A. safe',
        'expected': 0.0,  # ä¸åŒé€‰é¡¹
        'dataset': 'commonsenseqa'
    },
    {
        'name': 'Code Format Output',
        'prediction': '\\boxed{def solve(): return 50}',
        'ground_truth': '50',
        'expected': 0.0,  # æ ¼å¼é”™è¯¯
        'dataset': 'math'
    },
    {
        'name': 'Option Inference Prohibited',
        'prediction': 'E',
        'ground_truth': 'might dream',
        'expected': 0.0,  # ç¦æ­¢æ¨æ–­
        'dataset': 'commonsenseqa'
    },
    # ... æ·»åŠ æ‰€æœ‰12ä¸ªå·²çŸ¥è¯¯åˆ¤æ¡ˆä¾‹
]

@pytest.mark.parametrize('case', MISJUDGMENT_CASES)
def test_misjudgment_case(case, reward_computer):
    """æµ‹è¯•å·²çŸ¥è¯¯åˆ¤æ¡ˆä¾‹æ˜¯å¦è¢«ä¿®å¤"""
    reward = reward_computer.compute_reward(
        problem='',
        prediction=case['prediction'],
        ground_truth=case['ground_truth'],
        problem_type=case.get('problem_type', 'qa'),
        metadata={'source': case['dataset']},
        test='',
        entry_point=''
    )

    assert reward == case['expected'], f"Failed on case: {case['name']}"
```

### é˜¶æ®µ3: éƒ¨ç½²å’Œç›‘æ§

#### 3.1 ç”Ÿæˆæ”¹è¿›æŠ¥å‘Š

**è¿è¡Œè®­ç»ƒ**:
```bash
python train.py --config config/training.yaml
```

**å¯¹æ¯”æŒ‡æ ‡**:
- ä¿®å¤å‰å‡†ç¡®ç‡: 64.9%
- ä¿®å¤åå‡†ç¡®ç‡: ?
- è¯¯åˆ¤ç‡å˜åŒ–: 12-20% â†’ ?

**ç”ŸæˆæŠ¥å‘Š**: `docs/evaluation_improvement_report.md`

#### 3.2 æŒç»­ç›‘æ§

åœ¨ `src/reward_computer.py` ä¸­æ·»åŠ ç›‘æ§:

```python
class RewardComputer:
    def __init__(self, ...):
        self.eval_stats = {
            'gsm8k': {'calls': 0, 'success': 0, 'failures': 0},
            'math': {'calls': 0, 'success': 0, 'failures': 0},
            'qa': {'calls': 0, 'success': 0, 'failures': 0},
            # ...
        }

    def compute_reward(self, ...):
        dataset = self._identify_dataset(sample)
        self.eval_stats[dataset]['calls'] += 1

        try:
            reward = self._evaluate(...)
            self.eval_stats[dataset]['success'] += 1
            return reward
        except Exception as e:
            self.eval_stats[dataset]['failures'] += 1
            logger.error(f"Evaluation failed for {dataset}: {e}")
            raise

    def print_stats(self):
        """æ‰“å°è¯„ä¼°ç»Ÿè®¡"""
        for dataset, stats in self.eval_stats.items():
            success_rate = stats['success'] / stats['calls'] if stats['calls'] > 0 else 0
            print(f"{dataset}: {stats['calls']} calls, {success_rate:.2%} success")
```

---

## é¢„æœŸæ•ˆæœ

### å®šé‡æŒ‡æ ‡

| æŒ‡æ ‡ | å½“å‰ | é¢„æœŸ | æå‡ |
|------|------|------|------|
| **æ€»å‡†ç¡®ç‡** | 64.9% | 70-75% | +5.1-10.1% |
| **è¯¯åˆ¤ç‡** | 12-20% | <5% | -60-75% |
| **Mathå‡†ç¡®ç‡** | æ³¢åŠ¨å¤§ | +5-8% | ç¨³å®šæ€§æå‡ |
| **Codeå‡†ç¡®ç‡** | 80-100% | +3-5% | æ¥è¿‘ä¸Šé™ |
| **QAå‡†ç¡®ç‡** | ç›¸å¯¹ç¨³å®š | +2-3% | å°å¹…æå‡ |

### å®šæ€§æ”¹è¿›

1. **GSM8K**: å‡†ç¡®æå– `####` åçš„æœ€ç»ˆç­”æ¡ˆï¼Œä¸å—ä¸­é—´æ­¥éª¤å¹²æ‰°
2. **Math**: ä¼˜å…ˆä½¿ç”¨ `meta.short_answer`ï¼Œå¤„ç†LaTeXæ ¼å¼
3. **Code**: å®Œå…¨ä¾èµ–æµ‹è¯•æ‰§è¡Œï¼Œä¸å†è¯¯åˆ¤å˜é‡åå·®å¼‚
4. **QA**: ç¦æ­¢æ¨æ–­é€‰é¡¹ç­‰ä»·æ€§ï¼Œå‡å°‘"è„‘è¡¥"é”™è¯¯
5. **æ ¼å¼é²æ£’æ€§**: è¯†åˆ«ä»£ç æ³„æ¼ã€ç©ºè¾“å‡ºç­‰å¼‚å¸¸æ ¼å¼

### æ¡ˆä¾‹å¯¹æ¯”

#### æ¡ˆä¾‹1: GSM8K #### æå–

**ä¿®å¤å‰**:
```python
Prediction: "24"
Ground Truth: "Natalia sold 48/2 = <<48/2=24>>24...#### 72"
Judge: 1.0 âœ…  # é”™è¯¯ï¼šæå–åˆ°ä¸­é—´è®¡ç®—24
```

**ä¿®å¤å**:
```python
Prediction: "24"
Ground Truth: "...#### 72"
Extracted GT: "72"
Judge: 0.0 âŒ  # æ­£ç¡®ï¼š24 != 72
```

#### æ¡ˆä¾‹2: QAé€‰é¡¹æ¨æ–­

**ä¿®å¤å‰**:
```python
Prediction: "E"
Ground Truth: "might dream"
Judge: 1.0 âœ…  # é”™è¯¯ï¼šJudgeæ¨æ–­E=might dream
```

**ä¿®å¤å**:
```python
Prediction: "E"
Ground Truth: "might dream"
Judge: 0.0 âŒ  # æ­£ç¡®ï¼šç¦æ­¢æ¨æ–­
```

#### æ¡ˆä¾‹3: ä»£ç æ ¼å¼è¾“å‡º

**ä¿®å¤å‰**:
```python
Prediction: "\\boxed{def solve(): return 50}"
Ground Truth: "50"
Judge: 0.0 âŒ  # æ­£ç¡®åˆ¤é”™ï¼Œä½†åŸå› ä¸æ˜
```

**ä¿®å¤å**:
```python
Prediction: "\\boxed{def solve(): return 50}"
Extracted: None  # è¯†åˆ«ä¸ºä»£ç æ³„æ¼
Judge: 0.0 âŒ  # æ­£ç¡®åˆ¤é”™ï¼Œä¸”è®°å½•åŸå› ï¼š"ä»£ç æ³„æ¼"
```

---

## FAQ

### Q1: ä¸ºä»€ä¹ˆä¸ç›´æ¥ä¿®æ”¹ä»£ç ï¼Œè€Œæ˜¯å…ˆåˆ›å»ºé…ç½®æ–‡ä»¶ï¼Ÿ

**A**: è®¾è®¡å…ˆè¡Œï¼Œç¡®ä¿ç­–ç•¥æ­£ç¡®åå†å®æ–½ã€‚é…ç½®æ–‡ä»¶ä½œä¸ºè®¾è®¡æ–‡æ¡£ï¼Œæ˜ç¡®äº†æ¯ç§æ•°æ®é›†çš„è¯„ä¼°è§„åˆ™ï¼Œé¿å…ä»£ç å®ç°æ—¶é—æ¼æˆ–è¯¯è§£éœ€æ±‚ã€‚

### Q2: å¦‚æœæ–°å¢æ•°æ®é›†ï¼Œå¦‚ä½•æ·»åŠ æ”¯æŒï¼Ÿ

**A**: åœ¨ `config/judge_prompts.yaml` ä¸­æ·»åŠ æ–°çš„æ•°æ®é›†é…ç½®å³å¯ï¼š

```yaml
new_dataset:
  enabled: true
  description: "æ–°æ•°æ®é›†æè¿°"
  answer_extraction: {...}
  judge_prompt: |...
```

ç„¶ååœ¨ `dataset_mapping` ä¸­æ³¨å†Œï¼š

```yaml
dataset_mapping:
  by_source:
    new_dataset: "new_dataset"
```

### Q3: é…ç½®æ–‡ä»¶ä¿®æ”¹åéœ€è¦é‡å¯è®­ç»ƒå—ï¼Ÿ

**A**: æ˜¯çš„ã€‚é…ç½®æ–‡ä»¶åœ¨ `RewardComputer` åˆå§‹åŒ–æ—¶åŠ è½½ï¼Œä¿®æ”¹é…ç½®éœ€è¦é‡æ–°å¯åŠ¨è®­ç»ƒè¿›ç¨‹ã€‚

**æœªæ¥æ”¹è¿›**: å¯ä»¥å®ç°é…ç½®çƒ­é‡è½½ï¼Œæ— éœ€é‡å¯ã€‚

### Q4: å¦‚æœLLM Judgeè§£æå¤±è´¥æ€ä¹ˆåŠï¼Ÿ

**A**: å®ç°äº†å¤šå±‚fallbackæœºåˆ¶ï¼š

1. **é‡è¯•**: è§£æå¤±è´¥æ—¶é‡è¯•1æ¬¡ï¼ˆå·²å®ç°ï¼‰
2. **Fallbackåˆ°è§„åˆ™**: å¦‚æœJudgeå¤±è´¥ï¼Œä½¿ç”¨åŸºäºè§„åˆ™çš„æ¯”è¾ƒï¼ˆå¦‚Token F1ï¼‰
3. **è®°å½•æ—¥å¿—**: æ‰€æœ‰å¤±è´¥æ¡ˆä¾‹è®°å½•åˆ°æ—¥å¿—ï¼Œå®šæœŸreview

### Q5: Codeé¢˜ä¸ºä»€ä¹ˆç¦ç”¨LLM Judgeï¼Ÿ

**A**: Codeé¢˜æœ‰æ˜ç¡®çš„æµ‹è¯•ç”¨ä¾‹ï¼Œæ‰§è¡ŒéªŒè¯æ˜¯æœ€å‡†ç¡®çš„æ–¹æ³•ã€‚LLM Judgeåªä¼šåœ¨ä»¥ä¸‹æƒ…å†µfallbackä½¿ç”¨ï¼š

- æµ‹è¯•ç”¨ä¾‹ç¼ºå¤±
- ä»£ç æ‰§è¡Œè¶…æ—¶
- ä»£ç è¯­æ³•é”™è¯¯æ— æ³•æ‰§è¡Œ

å³ä½¿fallbackåˆ°Judgeï¼Œä¹Ÿä¼šåœ¨æ—¥å¿—ä¸­æ ‡è®° `âš ï¸ WARNING: Using semantic comparison for code task`ã€‚

### Q6: å¦‚ä½•ç›‘æ§Judgeæ€§èƒ½ï¼Ÿ

**A**: å®ç°äº†å¤šç»´åº¦ç›‘æ§ï¼š

1. **æˆåŠŸç‡**: æ¯ç§Judgeçš„è§£ææˆåŠŸç‡
2. **å»¶è¿Ÿ**: å¹³å‡å“åº”æ—¶é—´
3. **ä¸€è‡´æ€§**: ä¸fallbackæ–¹æ³•çš„ä¸€è‡´æ€§
4. **é‡‡æ ·æ—¥å¿—**: 10%çš„åˆ¤å®šè®°å½•è¯¦ç»†æ—¥å¿—ä¾›å®¡æŸ¥

ç»Ÿè®¡æ•°æ®ä¿å­˜åœ¨ `RewardComputer.eval_stats`ï¼Œè®­ç»ƒç»“æŸæ—¶æ‰“å°æ±‡æ€»ã€‚

### Q7: å¦‚æœå‘ç°æ–°çš„è¯¯åˆ¤æ¨¡å¼æ€ä¹ˆåŠï¼Ÿ

**A**: æµç¨‹ï¼š

1. **è®°å½•æ¡ˆä¾‹**: æ·»åŠ åˆ° `evaluation_cases/misjudged_cases.jsonl`
2. **åˆ†æåŸå› **: æ›´æ–° `docs/MISJUDGMENT_ANALYSIS.md`
3. **ä¿®æ”¹é…ç½®**: åœ¨ `config/judge_prompts.yaml` ä¸­è°ƒæ•´ç›¸å…³Judge prompt
4. **æ·»åŠ æµ‹è¯•**: åœ¨ `tests/test_misjudgment_cases.py` ä¸­æ·»åŠ å›å½’æµ‹è¯•
5. **éªŒè¯ä¿®å¤**: è¿è¡Œæµ‹è¯•ç¡®ä¿ä¿®å¤ç”Ÿæ•ˆ

### Q8: å‡†ç¡®ç‡æå‡ä¸åˆ°é¢„æœŸæ€ä¹ˆåŠï¼Ÿ

**A**: è¯Šæ–­æ­¥éª¤ï¼š

1. **æ£€æŸ¥é…ç½®**: ç¡®è®¤é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ
2. **éªŒè¯è¯†åˆ«**: æ£€æŸ¥æ•°æ®é›†è¯†åˆ«æ˜¯å¦æ­£ç¡®
   ```python
   # æ·»åŠ è°ƒè¯•æ—¥å¿—
   logger.info(f"Sample source: {sample.get('source')}, using judge: {judge_name}")
   ```
3. **åˆ†æå¤±è´¥æ¡ˆä¾‹**: æŸ¥çœ‹æ–°çš„è¯¯åˆ¤æ¨¡å¼
4. **A/Bæµ‹è¯•**: å¯¹æ¯”æ–°æ—§Judgeçš„åˆ¤å®šå·®å¼‚
5. **å¢é‡ä¿®å¤**: é€ä¸ªæ•°æ®é›†å¯ç”¨ä¼˜åŒ–ï¼Œå®šä½é—®é¢˜

---

## æ€»ç»“

æœ¬æŒ‡å—æä¾›äº†å®Œæ•´çš„å®æ–½æ–¹æ¡ˆï¼Œä»é—®é¢˜åˆ†æã€è®¾è®¡æ–¹æ¡ˆã€é…ç½®æ–‡ä»¶åˆ°æµ‹è¯•éªŒè¯ã€‚

**å…³é”®è¦ç‚¹**:

1. âœ… **å·²å®Œæˆ**: åˆ†ææ–‡æ¡£ã€é…ç½®æ–‡ä»¶ã€å®æ–½æŒ‡å—
2. â¸ï¸ **å¾…å®æ–½**: ä»£ç ä¿®æ”¹ï¼ˆç­‰å¾…ç­–ç•¥ç¡®è®¤ï¼‰
3. ğŸ¯ **ç›®æ ‡**: è¯¯åˆ¤ç‡<5%ï¼Œå‡†ç¡®ç‡70-75%
4. ğŸ“Š **ç›‘æ§**: æŒç»­è·Ÿè¸ªå„Judgeæ€§èƒ½
5. ğŸ”„ **è¿­ä»£**: å‘ç°æ–°é—®é¢˜åŠæ—¶ä¿®å¤

**ä¸‹ä¸€æ­¥**:
è¯·å®¡æŸ¥æœ¬æŒ‡å—å’Œé…ç½®æ–‡ä»¶ï¼Œç¡®è®¤ç­–ç•¥åæˆ‘ä»¬å†è¿›è¡Œä»£ç ä¿®æ”¹å’Œæµ‹è¯•ã€‚

---

## ç›¸å…³æ–‡æ¡£

- [è¯¯åˆ¤åˆ†ææŠ¥å‘Š](./MISJUDGMENT_ANALYSIS.md)
- [è¯¦ç»†é”™è¯¯åˆ†æ](./ERROR_PATTERNS_DETAILED.md)
- [Judgeé…ç½®æ–‡ä»¶](../config/judge_prompts.yaml)
- [è®­ç»ƒæ—¥å¿—](../logs/train_restored_v10.log)

**æ–‡æ¡£ç»“æŸ**
