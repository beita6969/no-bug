# WandBç›‘æ§ç³»ç»Ÿ - å¿«é€Ÿå¼€å§‹æŒ‡å—

## ğŸ“š æ–‡æ¡£æ¦‚è§ˆ

æœ¬é¡¹ç›®æä¾›äº†å®Œæ•´çš„WandBç›‘æ§ç³»ç»Ÿè®¾è®¡å’Œå®ç°ä»£ç ã€‚åŒ…å«ä»¥ä¸‹æ–‡æ¡£:

1. **è®¾è®¡æ–‡æ¡£**: `docs/WANDB_MONITORING_DESIGN.md` - è¯¦ç»†çš„ç³»ç»Ÿåˆ†æå’Œè®¾è®¡æ–¹æ¡ˆ
2. **å®ç°ä»£ç **: `src/wandb_metrics_collectors.py` - å¯å¤ç”¨çš„æŒ‡æ ‡æ”¶é›†å·¥å…·ç±»
3. **è¡¥ä¸æŒ‡å—**: `docs/WANDB_PATCH_GUIDE.md` - æ‰‹åŠ¨åº”ç”¨è¡¥ä¸çš„è¯¦ç»†æ­¥éª¤
4. **è¡¥ä¸è„šæœ¬**: `scripts/apply_wandb_patch.py` - è‡ªåŠ¨/åŠè‡ªåŠ¨åº”ç”¨è¡¥ä¸çš„å·¥å…·

---

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

### æ–°å¢ç›‘æ§ç»´åº¦

âœ… **æ•°æ®é›†ç»´åº¦ç»Ÿè®¡** (P0)
- ä¸ºæ¯ä¸ªæ•°æ®é›†å•ç‹¬ç»Ÿè®¡å‡†ç¡®ç‡
- æ”¯æŒ: GSM8K, MATH, HotpotQA, HumanEval, CommonsenseQA, MMLU
- è®­ç»ƒé›†å’ŒéªŒè¯é›†å‡æ”¯æŒ

âœ… **LLM Judgeæ€§èƒ½ç›‘æ§** (P1)
- æˆåŠŸç‡ã€å¤±è´¥ç‡ç»Ÿè®¡
- åˆ¤å†³åˆ†å¸ƒåˆ†æ
- æŒ‰æ•°æ®é›†çš„Judgeæ€§èƒ½

âœ… **éªŒè¯é›†è¯¦ç»†åˆ†æ** (P1)
- æŒ‰æ•°æ®é›†åˆ†è§£çš„éªŒè¯æ€§èƒ½
- æˆæœ¬vså‡†ç¡®ç‡å…³è”åˆ†æ

âœ… **æˆæœ¬ç»Ÿè®¡** (P2)
- ç´¯ç§¯æˆæœ¬è¿½è¸ª
- å¹³å‡æˆæœ¬peræ ·æœ¬
- Executor/Judgeè°ƒç”¨æ¬¡æ•°

### WandBä»ªè¡¨æ¿é¢„è§ˆ

å®æ–½åå¯ç›‘æ§çš„å…³é”®æŒ‡æ ‡:

```yaml
# æ•°æ®é›†å‡†ç¡®ç‡
dataset/gsm8k/accuracy: 85.2%
dataset/math/accuracy: 42.1%
dataset/hotpotqa/accuracy: 68.3%
dataset/humaneval/accuracy: 55.7%

# LLM Judgeæ€§èƒ½
judge/success_rate: 0.85
judge/parse_failure_rate: 0.10
judge/api_failure_rate: 0.05
judge/correct_ratio: 0.706

# æˆæœ¬ç»Ÿè®¡
cost/total_cost: $12.34
cost/avg_cost_per_sample: $0.0123
cost/executor_calls: 1000
cost/judge_calls: 800

# éªŒè¯é›†åˆ†è§£
val/gsm8k/accuracy: 83.5%
val/math/accuracy: 40.2%
val/hotpotqa/accuracy: 65.8%
```

---

## ğŸš€ å¿«é€Ÿå®æ–½

### æ–¹å¼1: æµ‹è¯•å·¥å…·ç±» (æ¨èå…ˆåš)

```bash
# 1. æµ‹è¯•æŒ‡æ ‡æ”¶é›†å™¨
python3 src/wandb_metrics_collectors.py

# é¢„æœŸè¾“å‡º:
# ğŸ§ª æµ‹è¯•DatasetMetricsCollector
# WandBæ—¥å¿—:
#   dataset/gsm8k/accuracy: 66.66666666666666
#   dataset/gsm8k/count: 3
#   ...
# âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼
```

### æ–¹å¼2: æ‰‹åŠ¨åº”ç”¨è¡¥ä¸ (æ¨è)

```bash
# 1. å¤‡ä»½åŸæ–‡ä»¶
cp src/grpo_trainer.py src/grpo_trainer.py.backup

# 2. æŸ¥çœ‹æ‰‹åŠ¨è¡¥ä¸æŒ‡å—
cat docs/WANDB_PATCH_GUIDE.md

# 3. ä½¿ç”¨ç¼–è¾‘å™¨æ‰“å¼€grpo_trainer.py
vim src/grpo_trainer.py
# æˆ–
code src/grpo_trainer.py

# 4. æŒ‰ç…§æŒ‡å—é€ä¸ªåº”ç”¨10ä¸ªè¡¥ä¸
# Patch 1-10 çš„å…·ä½“ä½ç½®å’Œä»£ç è§ WANDB_PATCH_GUIDE.md

# 5. éªŒè¯è¯­æ³•
python3 -m py_compile src/grpo_trainer.py

# 6. æµ‹è¯•å¯¼å…¥
python3 -c "from src.grpo_trainer import GRPOTrainer; print('âœ… å¯¼å…¥æˆåŠŸ')"
```

### æ–¹å¼3: åŠè‡ªåŠ¨åº”ç”¨è¡¥ä¸ (å®éªŒæ€§)

```bash
# 1. è¿è¡Œè¡¥ä¸è„šæœ¬ (dry run)
python3 scripts/apply_wandb_patch.py

# è¾“å‡ºä¼šæ˜¾ç¤º:
# âœ… Patch 1: æ·»åŠ å¯¼å…¥è¯­å¥
# âœ… Patch 2: åœ¨__init__ä¸­æ·»åŠ æˆæœ¬è¿½è¸ªå™¨
# âœ… Patch 3: åœ¨train_stepå¼€å§‹æ·»åŠ æ•°æ®é›†æ”¶é›†å™¨
# âš ï¸  Patch 4-5: éœ€è¦æ‰‹åŠ¨æ·»åŠ ...
# âœ… Patch 6: åœ¨train_stepæœ«å°¾æ·»åŠ wandbæ—¥å¿—
# âš ï¸  Patch 7-10: éœ€è¦æ‰‹åŠ¨æ·»åŠ ...

# 2. å¦‚æœæ»¡æ„ï¼Œå®é™…åº”ç”¨è¡¥ä¸
python3 -c "
from scripts.apply_wandb_patch import apply_patch_to_file
apply_patch_to_file('src/grpo_trainer.py', dry_run=False)
"

# 3. æ‰‹åŠ¨å®Œæˆå‰©ä½™çš„Patch 4-5å’Œ7-10 (å‚è€ƒWANDB_PATCH_GUIDE.md)
```

---

## ğŸ“Š éªŒè¯å®æ–½

### æ­¥éª¤1: æ£€æŸ¥è¯­æ³•

```bash
python3 -m py_compile src/grpo_trainer.py
```

### æ­¥éª¤2: æµ‹è¯•å¯¼å…¥

```bash
python3 -c "
from src.grpo_trainer import GRPOTrainer
from src.wandb_metrics_collectors import DatasetMetricsCollector
print('âœ… æ‰€æœ‰å¯¼å…¥æˆåŠŸ')
"
```

### æ­¥éª¤3: è¿è¡Œç¦»çº¿æµ‹è¯•

ä¿®æ”¹ `config/training.yaml`:

```yaml
wandb:
  enabled: true
  mode: offline  # ç¦»çº¿æ¨¡å¼æµ‹è¯•
  project: "aflow-roll-integration"
```

è¿è¡Œè®­ç»ƒ:

```bash
python3 train.py
```

æ£€æŸ¥æ—¥å¿—è¾“å‡º:

```bash
# åº”è¯¥çœ‹åˆ°æ–°çš„ç»Ÿï¿½ï¿½è¾“å‡º:
# ğŸ“Š æ•°æ®é›†ç»Ÿè®¡æ‘˜è¦:
#   gsm8k          :   2/  3 =  66.7%
#   math           :   1/  2 =  50.0%
#
# ğŸ¤– LLM Judgeç»Ÿè®¡ (æ€»è®¡: 100 æ¬¡):
#   æˆåŠŸ: 85 (85.0%)
#   ...
#
# ğŸ’° æˆæœ¬ç»Ÿè®¡:
#   æ€»æˆæœ¬: $0.0350
#   ...
```

### æ­¥éª¤4: æ£€æŸ¥WandBç¦»çº¿æ—¥å¿—

```bash
# æŸ¥çœ‹ç¦»çº¿æ—¥å¿—ç›®å½•
ls -la wandb/

# ä½¿ç”¨wandb CLIåŒæ­¥æ—¥å¿—
wandb sync wandb/offline-run-*

# æˆ–è€…ç›´æ¥æŸ¥çœ‹æ—¥å¿—å†…å®¹
cat wandb/offline-run-*/files/wandb-summary.json | jq .
```

### æ­¥éª¤5: åœ¨çº¿æµ‹è¯•

ç¡®è®¤ç¦»çº¿æµ‹è¯•æ— è¯¯åï¼Œä¿®æ”¹é…ç½®:

```yaml
wandb:
  enabled: true
  mode: online  # åœ¨çº¿æ¨¡å¼
  project: "aflow-roll-integration"
  api_key: "your_api_key_here"
```

è¿è¡Œè®­ç»ƒå¹¶è®¿é—®WandBä»ªè¡¨æ¿:

```bash
python3 train.py

# è®­ç»ƒå¼€å§‹åä¼šæ‰“å°URL:
# âœ… wandbåˆå§‹åŒ–å®Œæˆ
#   æ¨¡å¼: online
#   é¡¹ç›®: aflow-roll-integration
#   Runåç§°: grpo-training-20251123-120000
#   Run URL: https://wandb.ai/your-entity/aflow-roll-integration/runs/xxx
```

---

## ğŸ” æ•…éšœæ’æŸ¥

### é—®é¢˜1: å¯¼å…¥é”™è¯¯

```
ImportError: cannot import name 'DatasetMetricsCollector'
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
ls src/wandb_metrics_collectors.py

# æ£€æŸ¥Pythonè·¯å¾„
python3 -c "import sys; print('\n'.join(sys.path))"

# å¦‚æœéœ€è¦ï¼Œæ·»åŠ åˆ°PYTHONPATH
export PYTHONPATH="$PWD:$PYTHONPATH"
```

### é—®é¢˜2: æ•°æ®é›†ç»Ÿè®¡ä¸ºç©º

**åŸå› **: batchä¸­ç¼ºå°‘è¯¥æ•°æ®é›†çš„æ ·æœ¬

**è§£å†³æ–¹æ¡ˆ**:
```yaml
# æ£€æŸ¥config/training.yamlä¸­çš„domain_ratios
domain_ratios:
  math: 0.4
  code: 0.3
  qa: 0.3

# ç¡®ä¿æ•°æ®æ–‡ä»¶å­˜åœ¨
ls data/mixed/train_mixed*.jsonl

# æ£€æŸ¥æ•°æ®ä¸­çš„sourceå­—æ®µ
head -3 data/mixed/train_mixed_with_math.jsonl | jq .source
```

### é—®é¢˜3: LLM Judgeç»Ÿè®¡ä¸æ›´æ–°

**åŸå› **: `use_llm_judge=False`

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ£€æŸ¥reward_computeråˆå§‹åŒ–
# src/grpo_trainer.py ç¬¬198è¡Œ
self.reward_computer = RewardComputer(
    reward_weights=self.config.get('reward_weights'),
    use_llm_judge=True,  # â† ç¡®ä¿ä¸ºTrue
    llm_config={...}
)
```

### é—®é¢˜4: WandBç¦»çº¿æ—¥å¿—æœªç”Ÿæˆ

**è§£å†³æ–¹æ¡ˆ**:
```bash
# 1. æ£€æŸ¥é…ç½®
grep -A 5 "wandb:" config/training.yaml

# 2. è®¾ç½®ç¯å¢ƒå˜é‡
export WANDB_MODE=offline

# 3. é‡æ–°è¿è¡Œ
python3 train.py

# 4. æ£€æŸ¥ç›®å½•
ls -la wandb/
```

---

## ğŸ“ˆ é¢„æœŸæ•ˆæœå¯¹æ¯”

### å®æ–½å‰ (å½“å‰çŠ¶æ€)

```python
# WandBæ—¥å¿—
wandb.log({
    "train/loss": 0.5,
    "train/accuracy": 65.0,  # æ€»ä½“å‡†ç¡®ç‡
    "train/accuracy_math": 70.0,  # é—®é¢˜ç±»å‹ç»´åº¦
    "train/accuracy_code": 55.0,
    "train/accuracy_qa": 68.0,
})
```

**å±€é™æ€§**:
- âŒ æ— æ³•åŒºåˆ†GSM8Kå’ŒMATHçš„æ€§èƒ½
- âŒ æ— æ³•ç›‘æ§LLM Judgeè´¨é‡
- âŒ æ— æ³•è¿½è¸ªæˆæœ¬
- âŒ éªŒè¯é›†ç¼ºä¹è¯¦ç»†åˆ†æ

### å®æ–½å (å¢å¼ºçŠ¶æ€)

```python
# WandBæ—¥å¿—
wandb.log({
    # åŸæœ‰æŒ‡æ ‡
    "train/loss": 0.5,
    "train/accuracy": 65.0,
    "train/accuracy_math": 70.0,
    "train/accuracy_code": 55.0,
    "train/accuracy_qa": 68.0,

    # ğŸ†• æ•°æ®é›†ç»´åº¦
    "dataset/gsm8k/accuracy": 85.2,
    "dataset/gsm8k/count": 20,
    "dataset/math/accuracy": 42.1,
    "dataset/math/count": 15,
    "dataset/hotpotqa/accuracy": 68.3,
    "dataset/hotpotqa/count": 18,
    "dataset/humaneval/accuracy": 55.7,
    "dataset/humaneval/count": 12,

    # ğŸ†• LLM Judgeç›‘æ§
    "judge/success_rate": 0.85,
    "judge/parse_failure_rate": 0.10,
    "judge/api_failure_rate": 0.05,
    "judge/correct_ratio": 0.706,

    # ğŸ†• æˆæœ¬ç»Ÿè®¡
    "cost/total_cost": 12.34,
    "cost/avg_cost_per_sample": 0.0123,
    "cost/executor_calls": 1000,
    "cost/judge_calls": 800,
})
```

**ä¼˜åŠ¿**:
- âœ… å®Œæ•´çš„æ•°æ®é›†çº§æ€§èƒ½å¯è§æ€§
- âœ… LLM Judgeè´¨é‡ç›‘æ§
- âœ… æˆæœ¬è¿½è¸ªå’Œä¼˜åŒ–ä¾æ®
- âœ… éªŒè¯é›†è¯¦ç»†è¯Šæ–­èƒ½åŠ›

---

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### åœºæ™¯1: åˆ†æGSM8Kæ€§èƒ½ä¸‹é™

```python
import wandb

api = wandb.Api()
run = api.run("entity/project/run_id")

# æŸ¥è¯¢GSM8Kå‡†ç¡®ç‡å†å²
history = run.history(keys=['dataset/gsm8k/accuracy', 'train/step'])
print(history)

# æ£€æŸ¥æ˜¯å¦åœ¨æŸä¸ªstepåä¸‹é™
import pandas as pd
df = pd.DataFrame(history)
print(df[df['train/step'] > 100])  # æŸ¥çœ‹100æ­¥åçš„è¡¨ç°
```

### åœºæ™¯2: å¯¹æ¯”ä¸åŒæ•°æ®é›†çš„è¡¨ç°

```python
import wandb
import matplotlib.pyplot as plt

api = wandb.Api()
run = api.run("entity/project/run_id")

# è·å–æ‰€æœ‰æ•°æ®é›†çš„æœ€æ–°å‡†ç¡®ç‡
datasets = ['gsm8k', 'math', 'hotpotqa', 'humaneval', 'commonsenseqa', 'mmlu']
accuracies = []

for dataset in datasets:
    key = f'dataset/{dataset}/accuracy'
    acc = run.summary.get(key, 0)
    accuracies.append(acc)
    print(f"{dataset:15s}: {acc:5.1f}%")

# ç»˜åˆ¶æ¡å½¢å›¾
plt.bar(datasets, accuracies)
plt.ylabel('Accuracy (%)')
plt.title('Performance by Dataset')
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig('dataset_comparison.png')
print("âœ… å·²ä¿å­˜å›¾è¡¨: dataset_comparison.png")
```

### åœºæ™¯3: ç›‘æ§LLM Judgeå¥åº·åº¦

```python
import wandb

api = wandb.Api()
run = api.run("entity/project/run_id")

# æŸ¥è¯¢Judgeç»Ÿè®¡
judge_stats = {
    'success_rate': run.summary.get('judge/success_rate', 0),
    'parse_failure_rate': run.summary.get('judge/parse_failure_rate', 0),
    'api_failure_rate': run.summary.get('judge/api_failure_rate', 0),
    'correct_ratio': run.summary.get('judge/correct_ratio', 0),
}

print("ğŸ¤– LLM Judgeå¥åº·åº¦:")
for key, value in judge_stats.items():
    print(f"  {key:20s}: {value:.3f}")

# è­¦æŠ¥æ£€æŸ¥
if judge_stats['success_rate'] < 0.8:
    print("\nâš ï¸  è­¦å‘Š: JudgeæˆåŠŸç‡ä½äº80%ï¼")
if judge_stats['api_failure_rate'] > 0.1:
    print("âš ï¸  è­¦å‘Š: APIå¤±è´¥ç‡é«˜äº10%ï¼")
```

### åœºæ™¯4: æˆæœ¬ä¼˜åŒ–åˆ†æ

```python
import wandb

api = wandb.Api()
run = api.run("entity/project/run_id")

# æŸ¥è¯¢æˆæœ¬å†å²
history = run.history(keys=[
    'cost/total_cost',
    'cost/avg_cost_per_sample',
    'train/accuracy',
    'train/step'
])

import pandas as pd
df = pd.DataFrame(history)

# åˆ†ææˆæœ¬æ•ˆç‡
df['cost_per_accuracy'] = df['cost/avg_cost_per_sample'] / (df['train/accuracy'] / 100)
print("\nğŸ’° æˆæœ¬æ•ˆç‡åˆ†æ:")
print(df[['train/step', 'train/accuracy', 'cost/avg_cost_per_sample', 'cost_per_accuracy']].tail(10))

# æ‰¾å‡ºæœ€é«˜æ•ˆçš„step
best_step = df.loc[df['cost_per_accuracy'].idxmin()]
print(f"\nâœ¨ æœ€é«˜æ•ˆçš„è®­ç»ƒæ­¥: Step {best_step['train/step']:.0f}")
print(f"   å‡†ç¡®ç‡: {best_step['train/accuracy']:.1f}%")
print(f"   æˆæœ¬/æ ·æœ¬: ${best_step['cost/avg_cost_per_sample']:.6f}")
```

---

## ğŸ“š è¿›ä¸€æ­¥é˜…è¯»

- **è¯¦ç»†è®¾è®¡æ–‡æ¡£**: `docs/WANDB_MONITORING_DESIGN.md`
  - ç³»ç»Ÿæ¶æ„åˆ†æ
  - æŒ‡æ ‡è®¾è®¡è¯¦è§£
  - WandBä»ªè¡¨æ¿é…ç½®
  - æ€§èƒ½å¼€é”€åˆ†æ

- **å®ç°ä»£ç **: `src/wandb_metrics_collectors.py`
  - `DatasetMetricsCollector` - æ•°æ®é›†æŒ‡æ ‡æ”¶é›†
  - `JudgeMetricsCollector` - LLM Judgeç›‘æ§
  - `CostTracker` - æˆæœ¬è¿½è¸ª

- **è¡¥ä¸æŒ‡å—**: `docs/WANDB_PATCH_GUIDE.md`
  - 10ä¸ªè¡¥ä¸çš„è¯¦ç»†ä½ç½®å’Œä»£ç 
  - æ‰‹åŠ¨åº”ç”¨æ­¥éª¤
  - éªŒè¯æ¸…å•

---

## ğŸ¤ è´¡çŒ®

å¦‚æœä½ å‘ç°é—®é¢˜æˆ–æœ‰æ”¹è¿›å»ºè®®ï¼Œè¯·:

1. åˆ›å»ºIssueæè¿°é—®é¢˜
2. æäº¤Pull Requestä¿®å¤
3. æ›´æ–°ç›¸å…³æ–‡æ¡£

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªMITè®¸å¯è¯ã€‚

---

**æœ€åæ›´æ–°**: 2025-11-23
**ç»´æŠ¤è€…**: AI Training Team
