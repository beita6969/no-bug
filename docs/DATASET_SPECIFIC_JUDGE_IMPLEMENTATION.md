# æ•°æ®é›†ä¸“å±Judgeç³»ç»Ÿå®ç°å®Œæˆ

> **å®ç°æ—¥æœŸ**: 2025-11-23
> **ç‰ˆæœ¬**: V11 (Dataset-Specific Judge Edition)
> **æ ¸å¿ƒç†å¿µ**: é’ˆå¯¹ä¸åŒæ•°æ®é›†ä½¿ç”¨ä¸åŒçš„è¯„ä¼°ç­–ç•¥ï¼Œæé«˜åˆ¤å®šå‡†ç¡®æ€§

---

## ğŸ¯ å®ç°ç›®æ ‡

æ ¹æ®ç”¨æˆ·éœ€æ±‚"é’ˆå¯¹æ¯ä¸€ä¸ªæ•°æ®é›†çš„ç‰ˆæœ¬"ï¼Œå®ç°äº†ï¼š

1. **æ•°æ®é›†ä¸“å±Promptç³»ç»Ÿ** - ä¸º8ä¸ªæ•°æ®é›†é…ç½®ä¸“å±Judgeæç¤ºè¯
2. **è‡ªåŠ¨è·¯ç”±æœºåˆ¶** - æ ¹æ®sampleçš„sourceå­—æ®µè‡ªåŠ¨é€‰æ‹©å¯¹åº”ç­–ç•¥
3. **Fallbackæœºåˆ¶** - æœªçŸ¥æ•°æ®é›†è‡ªåŠ¨ä½¿ç”¨é€šç”¨Prompt
4. **é›¶ä¾µå…¥æ€§** - ä¿æŒæ¨¡å‹é€‰æ‹©operatorçš„å®Œå…¨çµæ´»åº¦

---

## ğŸ“ æ–°å¢æ–‡ä»¶

### 1. `src/judge_prompt_loader.py` (æ–°å¢)

**åŠŸèƒ½**: åŠ è½½å’Œç®¡ç†æ•°æ®é›†ä¸“å±çš„Judge Prompt

**æ ¸å¿ƒæ–¹æ³•**:
```python
class JudgePromptLoader:
    def get_judge_prompt(source, problem_type) -> str:
        """æ ¹æ®æ•°æ®é›†æ¥æºè¿”å›ä¸“å±Prompt"""

    def should_use_test_execution(source) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨æµ‹è¯•æ‰§è¡Œï¼ˆCodeæ•°æ®é›†ï¼‰"""

    def get_dataset_config(source) -> Dict:
        """è·å–å®Œæ•´çš„æ•°æ®é›†é…ç½®"""
```

**ç‰¹æ€§**:
- âœ… æ”¯æŒ8ä¸ªæ•°æ®é›†ï¼šGSM8K, Math, HotpotQA, SQuAD v2, CommonsenseQA, MMLU, HumanEval, MBPP
- âœ… è‡ªåŠ¨ä»`config/judge_prompts.yaml`åŠ è½½é…ç½®
- âœ… æä¾›fallbackæœºåˆ¶ï¼ˆæœªçŸ¥æ•°æ®é›†ä½¿ç”¨é€šç”¨promptï¼‰
- âœ… æ”¯æŒç¦ç”¨ç‰¹å®šæ•°æ®é›†çš„LLM Judgeï¼ˆå¦‚Codeæ•°æ®é›†ä½¿ç”¨test_executionï¼‰

---

### 2. `config/judge_prompts.yaml` (å·²å­˜åœ¨)

**å†…å®¹**: 8ä¸ªæ•°æ®é›†çš„ä¸“å±Judge Prompté…ç½®

**ç»“æ„**:
```yaml
gsm8k:
  enabled: true
  description: "Grade School Math 8K"
  judge_prompt: |
    You are a mathematical equivalence evaluator for GSM8K problems.
    **Special Rules for GSM8K**:
    1. The ground truth may end with "#### ANSWER"
    2. Extract ONLY the final numerical value from "#### NUMBER"
    ...

hotpotqa:
  enabled: true
  description: "HotpotQA - å¤šè·³æ¨ç†é—®ç­”"
  judge_prompt: |
    ğŸš« **PROHIBITION #1: No Inference of Option Labels**
    - If Prediction="E" and Ground Truth="might dream":
      â†’ Judge as **False** (Do NOT assume E means "might dream")
    ...

humaneval:
  enabled: false  # ä½¿ç”¨æµ‹è¯•æ‰§è¡Œè€ŒéLLM Judge
  evaluation_method: "test_execution"
  ...
```

**å…³é”®ç‰¹æ€§**:
- æ¯ä¸ªæ•°æ®é›†æœ‰ä¸“å±çš„è¯„ä¼°è§„åˆ™
- GSM8K: ä¸“é—¨å¤„ç†`####`æ ¼å¼å’Œ`<<calc>>`æ ‡è®°
- HotpotQA/CommonsenseQA: ç¦æ­¢æ¨æ–­é€‰é¡¹å­—æ¯å¯¹åº”å†…å®¹
- Math: æ”¯æŒLaTeXå’Œå¤šç§è¡¨è¾¾å½¢å¼
- HumanEval/MBPP: ä½¿ç”¨æµ‹è¯•æ‰§è¡Œï¼Œä¸ç”¨LLM Judge

---

### 3. `tests/test_judge_system.py` (æ–°å¢)

**åŠŸèƒ½**: éªŒè¯Judgeç³»ç»Ÿçš„æ­£ç¡®æ€§

**æµ‹è¯•å†…å®¹**:
1. âœ… åŠ è½½å™¨åŸºæœ¬åŠŸèƒ½ï¼ˆåŠ è½½9ä¸ªæ•°æ®é›†é…ç½®ï¼‰
2. âœ… ä¸åŒæ•°æ®é›†Promptå†…å®¹éªŒè¯
3. âœ… Codeæ•°æ®é›†çš„test_executionæ ‡å¿—
4. âœ… æ•°æ®é›†æ˜ å°„è¡¨æ­£ç¡®æ€§
5. âœ… Promptæ ¼å¼åŒ–åŠŸèƒ½

**è¿è¡Œç»“æœ**:
```bash
$ python3 tests/test_judge_system.py
âœ… åŠ è½½å™¨åˆå§‹åŒ–æˆåŠŸ
æ€»æ•°æ®é›†é…ç½®: 9
å¯ç”¨æ•°æ®é›†: gsm8k, math, hotpotqa, squad_v2, commonsenseqa, mmlu, monitoring
ç¦ç”¨æ•°æ®é›†: humaneval, mbpp
ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼
```

---

## ğŸ”§ ä¿®æ”¹çš„æ–‡ä»¶

### 1. `src/reward_computer.py`

**ä¿®æ”¹å†…å®¹**:

#### A. å¯¼å…¥JudgePromptLoader
```python
# src/reward_computer.py:15-20
try:
    from .answer_extractor import AnswerExtractor
    from .judge_prompt_loader import JudgePromptLoader  # æ–°å¢
except ImportError:
    from answer_extractor import AnswerExtractor
    from judge_prompt_loader import JudgePromptLoader  # æ–°å¢
```

#### B. åˆå§‹åŒ–JudgePromptLoader
```python
# src/reward_computer.py:69-82
self.judge_prompt_loader = None
if use_llm_judge:
    self._init_llm_judge_client(llm_config)
    # åˆå§‹åŒ–PromptåŠ è½½å™¨
    try:
        self.judge_prompt_loader = JudgePromptLoader()
        stats = self.judge_prompt_loader.get_stats()
        print(f"  âœ… Judge PromptåŠ è½½å™¨åˆå§‹åŒ–æˆåŠŸ")
        print(f"     å·²åŠ è½½ {stats['total_datasets']} ä¸ªæ•°æ®é›†é…ç½®")
    except Exception as e:
        print(f"  âš ï¸  Judge PromptåŠ è½½å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        self.judge_prompt_loader = None
```

#### C. ä¿®æ”¹`_llm_judge_compare`æ–¹æ³•
```python
# src/reward_computer.py:128-175
def _llm_judge_compare(
    self,
    problem: str,
    prediction: str,
    ground_truth: str,
    problem_type: str,
    source: Optional[str] = None  # ğŸ†• æ–°å¢å‚æ•°
) -> bool:
    # ğŸ†• ä½¿ç”¨æ•°æ®é›†ä¸“å±Promptï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if self.judge_prompt_loader:
        query_prompt_template = self.judge_prompt_loader.get_judge_prompt(
            source=source,
            problem_type=problem_type
        )
        query_prompt = query_prompt_template.format(
            problem=problem,
            prediction=prediction,
            ground_truth=ground_truth
        )
    else:
        # Fallback: ä½¿ç”¨åŸæœ‰çš„é€šç”¨prompt
        query_prompt = self._get_legacy_prompt(problem, prediction, ground_truth)
```

#### D. æ–°å¢`_get_legacy_prompt`æ–¹æ³•
```python
# src/reward_computer.py:300-354
def _get_legacy_prompt(self, problem: str, prediction: str, ground_truth: str) -> str:
    """è·å–åŸæœ‰çš„é€šç”¨Promptï¼ˆå‘åå…¼å®¹ï¼‰"""
    return f"""You are a precise mathematical and logical equivalence evaluator..."""
```

#### E. ä¿®æ”¹`compute_reward`æ–¹æ³•
```python
# src/reward_computer.py:356-400
def compute_reward(
    self,
    ...,
    source: Optional[str] = None  # ğŸ†• æ–°å¢å‚æ•°
) -> float:
    ...
    if self.use_llm_judge:
        is_correct = self._llm_judge_compare(
            ...,
            source=source  # ğŸ†• ä¼ é€’sourceå‚æ•°
        )
```

**å½±å“**:
- âœ… ä¿æŒå‘åå…¼å®¹ï¼ˆsource=Noneæ—¶ä½¿ç”¨é€šç”¨Promptï¼‰
- âœ… ä¸å½±å“æ¨¡å‹è¡Œä¸ºï¼Œåªå½±å“ç­”æ¡ˆè¯„ä¼°æ–¹å¼
- âœ… è‡ªåŠ¨æ ¹æ®sourceé€‰æ‹©æœ€ä½³è¯„ä¼°ç­–ç•¥

---

### 2. `src/grpo_trainer.py`

**ä¿®æ”¹å†…å®¹**:

#### è®­ç»ƒå¾ªç¯ä¸­ä¼ é€’source
```python
# src/grpo_trainer.py:358-367
reward = self.reward_computer.compute_reward(
    problem=problem,
    prediction=answer,
    ground_truth=ground_truth,
    problem_type=problem_type,
    metadata=metadata,
    test=sample.get('test', ''),
    entry_point=sample.get('entry_point', ''),
    source=sample.get('source', None)  # ğŸ†• æ–°å¢
)
```

#### éªŒè¯é›†è¯„ä¼°ä¸­ä¼ é€’source
```python
# src/grpo_trainer.py:712-720
correctness = self.reward_computer.compute_reward(
    problem=problem,
    prediction=answer,
    ground_truth=ground_truth,
    problem_type=problem_type,
    test=sample.get('test', ''),
    entry_point=sample.get('entry_point', ''),
    source=sample.get('source', None)  # ğŸ†• æ–°å¢
)
```

**å½±å“**:
- âœ… è‡ªåŠ¨ä»sampleä¸­æå–sourceå­—æ®µ
- âœ… ä¸éœ€è¦ä¿®æ”¹æ•°æ®åŠ è½½é€»è¾‘ï¼ˆsourceå­—æ®µå·²å­˜åœ¨äºæ•°æ®ä¸­ï¼‰
- âœ… ä¸å½±å“è®­ç»ƒæµç¨‹ï¼Œåªå½±å“å¥–åŠ±è®¡ç®—

---

## ğŸ” æ•°æ®é›†ä¸“å±ç­–ç•¥è¯´æ˜

### GSM8K (Grade School Math)
```yaml
å…³é”®ç‰¹æ€§:
- è¯†åˆ«"#### æ•°å­—"æ ¼å¼ä½œä¸ºæœ€ç»ˆç­”æ¡ˆ
- å¿½ç•¥ä¸­é—´çš„"<<48/2=24>>"è®¡ç®—æ ‡è®°
- ç§»é™¤å•ä½ï¼ˆ$, hoursç­‰ï¼‰
- æ•°å€¼æ¯”è¾ƒå…è®¸0.01è¯¯å·®
```

### Math Dataset (ç«èµ›çº§æ•°å­¦)
```yaml
å…³é”®ç‰¹æ€§:
- ä¼˜å…ˆä½¿ç”¨meta.short_answerå­—æ®µ
- æ”¯æŒLaTeXè¡¨è¾¾å¼ï¼ˆ\frac, \sqrt, \boxedï¼‰
- å…è®¸ç­‰ä»·å½¢å¼ï¼ˆ1/2 = 0.5 = 50%ï¼‰
- ä»£æ•°ç­‰ä»·æ€§åˆ¤å®š
```

### HotpotQA & CommonsenseQA (é€‰é¡¹é¢˜)
```yaml
å…³é”®ç‰¹æ€§:
- ğŸš« ç¦æ­¢æ¨æ–­ï¼šé¢„æµ‹"E" â‰  çœŸå€¼"might dream"
- âœ… å…è®¸åå‘ï¼šé¢„æµ‹"might dream" = çœŸå€¼"E"
- æ ‡å‡†åŒ–ï¼šlowercase, remove articles, remove punctuation
- å­ä¸²åŒ¹é…ï¼š"The answer is Paris" åŒ…å« "Paris"
```

### HumanEval & MBPP (ä»£ç é¢˜)
```yaml
ç­–ç•¥:
- enabled: false (ç¦ç”¨LLM Judge)
- evaluation_method: "test_execution"
- ä½¿ç”¨æµ‹è¯•ç”¨ä¾‹æ‰§è¡ŒéªŒè¯ï¼Œè€Œéæ–‡æœ¬æ¯”è¾ƒ
```

---

## ğŸ“Š é¢„æœŸæ•ˆæœ

### è¯¯åˆ¤ç‡æ”¹å–„

| æ•°æ®é›† | ä¹‹å‰è¯¯åˆ¤ç±»å‹ | ä¿®å¤å |
|-------|------------|--------|
| **GSM8K** | æœªè¯†åˆ«`####`æ ¼å¼ | âœ… ä¸“é—¨å¤„ç† |
| **Math** | LaTeXæ ¼å¼å·®å¼‚ | âœ… æ ‡å‡†åŒ– |
| **HotpotQA** | é€‰é¡¹å­—æ¯æ¨æ–­ | âœ… ä¸¥æ ¼ç¦æ­¢ |
| **CommonsenseQA** | åŒä¸Š | âœ… ä¸¥æ ¼ç¦æ­¢ |
| **HumanEval** | æ–‡æœ¬æ¯”è¾ƒä¸å‡† | âœ… æµ‹è¯•æ‰§è¡Œ |

### å‡†ç¡®ç‡æå‡ä¼°è®¡

- **æ€»ä½“å‡†ç¡®ç‡**: 64.9% â†’ **72-78%** (+7-13%)
- **GSM8K**: +5-8% (æ ¼å¼é—®é¢˜ä¿®å¤)
- **HotpotQA/CommonsenseQA**: +3-5% (é€‰é¡¹æ¨æ–­ç¦æ­¢)
- **Math**: +2-3% (LaTeXå¤„ç†æ”¹è¿›)

---

## âœ… ç³»ç»Ÿç‰¹æ€§

### 1. é›¶ä¾µå…¥æ€§è®¾è®¡
- âœ… **ä¸å½±å“æ¨¡å‹è®­ç»ƒ**: RLä¼˜åŒ–è¿‡ç¨‹å®Œå…¨ä¸å˜
- âœ… **ä¸å½±å“operatoré€‰æ‹©**: æ¨¡å‹ä»ç„¶è‡ªç”±é€‰æ‹©workflowç»“æ„
- âœ… **ä¸å½±å“æ¨ç†è¿‡ç¨‹**: åªåœ¨æœ€åè¯„ä¼°é˜¶æ®µç”Ÿæ•ˆ
- âœ… **å‘åå…¼å®¹**: source=Noneæ—¶ä½¿ç”¨é€šç”¨Prompt

### 2. çµæ´»æ€§ä¿è¯
- âœ… **å¯é…ç½®**: æ‰€æœ‰è§„åˆ™åœ¨YAMLä¸­å®šä¹‰ï¼Œæ˜“äºä¿®æ”¹
- âœ… **å¯æ‰©å±•**: æ·»åŠ æ–°æ•°æ®é›†åªéœ€ä¿®æ”¹YAML
- âœ… **å¯ç¦ç”¨**: æ¯ä¸ªæ•°æ®é›†å¯ä»¥å•ç‹¬ç¦ç”¨
- âœ… **Fallbackæœºåˆ¶**: æœªçŸ¥æ•°æ®é›†è‡ªåŠ¨é™çº§ä¸ºé€šç”¨è¯„ä¼°

### 3. é²æ£’æ€§
- âœ… **é”™è¯¯å®¹å¿**: åŠ è½½å¤±è´¥è‡ªåŠ¨ä½¿ç”¨é€šç”¨Prompt
- âœ… **ç‰ˆæœ¬å…¼å®¹**: æ”¯æŒæ²¡æœ‰sourceå­—æ®µçš„æ—§æ•°æ®
- âœ… **æ—¥å¿—å®Œå–„**: è¯¦ç»†è®°å½•ä½¿ç”¨çš„Promptç±»å‹

---

## ğŸš€ ä½¿ç”¨ç¤ºä¾‹

### è®­ç»ƒæ—¶è‡ªåŠ¨åº”ç”¨

```python
# æ•°æ®æ ¼å¼ï¼ˆå·²æœ‰ï¼‰
sample = {
    'problem': 'Natalia sold clips...',
    'ground_truth': '...#### 72',
    'problem_type': 'math',
    'source': 'gsm8k'  # â† å…³é”®å­—æ®µ
}

# è®­ç»ƒå™¨è‡ªåŠ¨è¯†åˆ«å¹¶ä½¿ç”¨GSM8Kä¸“å±Prompt
reward = reward_computer.compute_reward(
    problem=sample['problem'],
    prediction=answer,
    ground_truth=sample['ground_truth'],
    problem_type=sample['problem_type'],
    source=sample['source']  # â† è‡ªåŠ¨ä¼ é€’
)
# â†’ ä½¿ç”¨GSM8Kä¸“å±Judgeè§„åˆ™è¯„ä¼°
```

### ä¸åŒæ•°æ®é›†çš„è¡Œä¸º

```python
# GSM8Kæ ·æœ¬
source='gsm8k' â†’ ä½¿ç”¨GSM8K Promptï¼ˆè¯†åˆ«####æ ¼å¼ï¼‰

# HotpotQAæ ·æœ¬
source='hotpotqa' â†’ ä½¿ç”¨HotpotQA Promptï¼ˆç¦æ­¢é€‰é¡¹æ¨æ–­ï¼‰

# HumanEvalæ ·æœ¬
source='humaneval' â†’ è·³è¿‡LLM Judgeï¼Œä½¿ç”¨æµ‹è¯•æ‰§è¡Œ

# æœªçŸ¥æ•°æ®é›†
source='new_dataset' â†’ Fallbackåˆ°é€šç”¨Prompt

# æ—§æ•°æ®ï¼ˆæ— sourceå­—æ®µï¼‰
source=None â†’ Fallbackåˆ°é€šç”¨Prompt
```

---

## ğŸ§ª æµ‹è¯•ä¸éªŒè¯

### è¿è¡Œæµ‹è¯•

```bash
cd /home/yijia/.claude/11/integrated_aflow_roll
python3 tests/test_judge_system.py
```

### é¢„æœŸè¾“å‡º

```
============================================================
æµ‹è¯•1: Judge PromptåŠ è½½å™¨åŸºæœ¬åŠŸèƒ½
============================================================
âœ… åŠ è½½å™¨åˆå§‹åŒ–æˆåŠŸ
æ€»æ•°æ®é›†é…ç½®: 9
å¯ç”¨æ•°æ®é›†: gsm8k, math, hotpotqa, squad_v2, commonsenseqa, mmlu
ç¦ç”¨æ•°æ®é›†: humaneval, mbpp

[GSM8K Prompt]
åŒ…å«'####': True
åŒ…å«'<<calc>>': True
åŒ…å«'GSM8K': True

[HotpotQA Prompt]
åŒ…å«'PROHIBITION': True
åŒ…å«'might dream': True

[HumanEval] åº”è¯¥ä½¿ç”¨æµ‹è¯•æ‰§è¡Œ: True

ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ•°æ®é›†ä¸“å±Judgeç³»ç»Ÿå·¥ä½œæ­£å¸¸
```

---

## ğŸ“ é…ç½®ä¿®æ”¹æŒ‡å—

### æ·»åŠ æ–°æ•°æ®é›†

1. ç¼–è¾‘`config/judge_prompts.yaml`ï¼š

```yaml
new_dataset:
  enabled: true
  description: "æ–°æ•°æ®é›†è¯´æ˜"
  judge_prompt: |
    You are an answer evaluator for [dataset name].

    **Special Rules**:
    1. ...
    2. ...

    **Prediction**: {prediction}
    **Ground Truth**: {ground_truth}

    {output_format}
```

2. æ·»åŠ æ˜ å°„ï¼š

```yaml
dataset_mapping:
  by_source:
    new_dataset: "new_dataset"
```

3. é‡å¯è®­ç»ƒï¼Œç³»ç»Ÿè‡ªåŠ¨åŠ è½½æ–°é…ç½®

### ä¿®æ”¹ç°æœ‰è§„åˆ™

ç›´æ¥ç¼–è¾‘`config/judge_prompts.yaml`å¯¹åº”æ•°æ®é›†çš„`judge_prompt`å­—æ®µï¼Œæ— éœ€ä¿®æ”¹ä»£ç ã€‚

### ç¦ç”¨æŸä¸ªæ•°æ®é›†çš„LLM Judge

```yaml
dataset_name:
  enabled: false  # ç¦ç”¨
  evaluation_method: "test_execution"  # å¯é€‰ï¼šæŒ‡å®šæ›¿ä»£æ–¹æ³•
```

---

## ğŸ’¡ å…³é”®æ´å¯Ÿ

1. **è¯„ä¼°ä¸è®­ç»ƒåˆ†ç¦»**: Judgeç³»ç»Ÿåªå½±å“rewardè®¡ç®—ï¼Œä¸å¹²é¢„workflowç”Ÿæˆ
2. **æ•°æ®é©±åŠ¨**: æ‰€æœ‰è§„åˆ™åœ¨é…ç½®æ–‡ä»¶ä¸­ï¼Œæ–¹ä¾¿è°ƒæ•´å’Œå®éªŒ
3. **æ¸è¿›å¼æ”¹è¿›**: å¯ä»¥é€æ­¥ä¸ºæ¯ä¸ªæ•°æ®é›†ä¼˜åŒ–Prompt
4. **å¯è§‚æµ‹æ€§**: æ—¥å¿—ä¸­ä¼šè®°å½•ä½¿ç”¨çš„Promptç±»å‹ï¼Œæ–¹ä¾¿è°ƒè¯•

---

## ğŸ‰ æ€»ç»“

æœ¬æ¬¡å®ç°å®Œæˆäº†**å®Œæ•´çš„æ•°æ®é›†ä¸“å±Judgeç³»ç»Ÿ**ï¼š

âœ… **3ä¸ªæ–°æ–‡ä»¶**:
- `src/judge_prompt_loader.py` - PromptåŠ è½½å™¨
- `config/judge_prompts.yaml` - 8ä¸ªæ•°æ®é›†é…ç½®
- `tests/test_judge_system.py` - æµ‹è¯•è„šæœ¬

âœ… **2ä¸ªä¿®æ”¹æ–‡ä»¶**:
- `src/reward_computer.py` - æ”¯æŒæ•°æ®é›†è·¯ç”±
- `src/grpo_trainer.py` - ä¼ é€’sourceå­—æ®µ

âœ… **æ ¸å¿ƒç‰¹æ€§**:
- é’ˆå¯¹8ä¸ªæ•°æ®é›†çš„ä¸“å±è¯„ä¼°ç­–ç•¥
- è‡ªåŠ¨æ ¹æ®sourceå­—æ®µé€‰æ‹©Prompt
- é›¶ä¾µå…¥æ€§è®¾è®¡ï¼Œä¿æŒRLçµæ´»åº¦
- å®Œæ•´çš„Fallbackå’Œé”™è¯¯å¤„ç†

âœ… **é¢„æœŸæå‡**:
- æ€»ä½“å‡†ç¡®ç‡ +7-13%
- å‡å°‘æ ¼å¼ç›¸å…³è¯¯åˆ¤ 60-75%
- æé«˜è¯„ä¼°çš„æ•°æ®é›†é€‚é…æ€§

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- **å®Œæ•´åˆ†æ**: `docs/MISJUDGMENT_ANALYSIS.md`
- **ä¼˜åŒ–æŒ‡å—**: `docs/JUDGE_OPTIMIZATION_GUIDE.md`
- **Bugä¿®å¤**: `docs/BUGFIX_V11_SUMMARY.md`
- **é…ç½®æ–‡ä»¶**: `config/judge_prompts.yaml`
